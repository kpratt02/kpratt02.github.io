[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Dr. Jacob Wallace\n   60 College St\n   jacob.wallace@yale.edu\n   jwswallace\n   Schedule an appointment\n\n\n\n\n\n   Thursdays\n   January–April 30, 2024\n   4:30–7:00 PM\n   Winslow Auditorium, LEPH\n   Slack"
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "Syllabus",
    "section": "Course objectives",
    "text": "Course objectives\nBy the end of this course, you (1) will be literate in the language of causal inference, (2) will communicate evaluation outcomes clearly, and (3) will understand the ethics and limits of data analysis by designing, critiquing, coding, and running rigorous, valid, and feasible evaluations of public sector programs focused on society’s most pressing problems.\nSpecifically, you’ll be able to:\n\nExplain the philosophy of causation\nIdentify and diagram program logic models\nOutline theories of change with directed acyclic graphs (DAGs)\nSummarize key threats to causal inference, identify these threats in evaluations, and mitigate these threats with research design\nDevelop rigorous and valid statistical measures\nRun statistical models\nExplain the theory, research design, methods, and results of evaluations to all types of stakeholders, from highly trained econometricians to the general public\nShare your analyses and data with the public\nIdentify ethical issues and limits in data science and program evaluation\nBecome curious and confident in consuming and producing evaluations"
  },
  {
    "objectID": "syllabus.html#course-philosophy",
    "href": "syllabus.html#course-philosophy",
    "title": "Syllabus",
    "section": "Course philosophy",
    "text": "Course philosophy\nClassical statistics classes spend substantial time covering probability theory, null hypothesis testing, and other statistical tests first developed hundreds of years ago. Some classes don’t use software or actual real data and instead live in the world of mathematical proofs. They can be math-heavy and full of often unintuitive concepts and equations.\nIn this class, we will take the opposite approach. We begin with data and learn how to tidy, wrangle, manipulate, and visualize it with code. Later in the semester we’ll turn to the powerful toolbox of causal inference approaches, but continue to keep the focus on data as we do so.\nIn other words, there’s way less of this:\n\\[\nf(x) = \\dfrac{1}{\\sqrt{2\\pi}} e^{-\\frac12 x^2}\n\\]\nAnd way more of this:\n\nsummary_monthly_temp &lt;- weather %&gt;%\n  group_by(month) %&gt;%\n  summarize(mean = mean(temp),\n            std_dev = sd(temp))\n\nOver the last decade there has been a revolution in statistical and scientific computing. Open source languages like R and Python have overtaken older (and expensive!) corporate software packages like SAS and SPSS, and there are now thousands of books and blog posts and other online resources with excellent tutorials about how to analyze pretty much any kind of data.\nThis class will expose you to R—one of the most popular, sought-after, and in-demand statistical programming languages. Armed with the foundation of R skills you’ll learn in this class, you’ll know enough to be able to find how to analyze any sort of data-based question in the future."
  },
  {
    "objectID": "syllabus.html#important-pep-talk",
    "href": "syllabus.html#important-pep-talk",
    "title": "Syllabus",
    "section": "Important pep talk!",
    "text": "Important pep talk!\nI promise you can succeed in this class.\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2—made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers and evaluators find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail me, etc.\n\n\n\n\n\n\n\n\n\n\n\n\nAlison Horst: Gator error"
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course materials",
    "text": "Course materials\nMost of the readings in this class are free.\n\nBooks\nThere are two official textbooks for the class. Both are available digitally and both are free.\n\nPaul J. Gertler et al., Impact Evaluation in Practice, 2nd ed. (Inter-American Development Bank; World Bank, 2016), https://openknowledge.worldbank.org/handle/10986/25030. (Free!)\nNick Huntington-Klein, The Effect: An Introduction to Research Design and Causality (CRC Press, 2021), https://theeffectbook.net/. (Free as a HTML version! The print version is coming soon and is pre-orderable at Amazon.)\n\nBoth of these books are written at a more general, easy-to-understand level with relatively minimal math. You do not need to understand all the equations and notation. If your eyes start to gloss over the Greek letters and subscripts, it’s okay. Try to learn them, but don’t stress out about it too much.\nIn previous versions of this class I used two different books instead of The Effect, and they’re still fantastic and I’d recommend checking them out. The Mixtape is a phenomenal, more detailed, more economics-focused, and mathier approach to these causal inference methods (and it’s free!), while ’Metrics Matter is a fairly canonical (and accessible!) book in the world of econometrics. I refer to these books a few times in the video lectures—don’t worry, you’ll get pretty much the same content in The Effect.\n\nScott Cunningham, Causal Inference: The Mixtape (New Haven, CT: Yale University Press, 2021), https://mixtape.scunning.com/. (Also free(!), but there’s also a print version for $35 that you might want to get for reference after the class is over)\nJoshua D. Angrist and Jörn-Steffen Pischke, Mastering ’Metrics: The Path from Cause to Effect (Princeton, NJ: Princeton University Press, 2015). ($25 used or $30 new at Amazon)\n\n\n\nArticles, book chapters, and other materials\nThere will also occasionally be additional articles and videos to read and watch. When this happens, links to these other resources will be included on the reading page for that week.\n\n\nR and RStudio\nYou will do all of your analysis with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nRStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets or more complicated analysis. Over the course of the semester, you’ll probably want to get around to installing R, RStudio, and other R packages on your computer and wean yourself off of RStudio.cloud. This isn’t necessary, but it’s helpful.\nYou can find instructions for installing R, RStudio, and all the tidyverse packages here.\n\n\nOnline help\nData science and statistical programming can be difficult. Computers are stupid and little errors in your code can cause hours of headache (even if you’ve been doing this stuff for years!).\nFortunately there are tons of online resources to help you with this. Two of the most important are StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful.\nSearching for help with R on Google can sometimes be tricky because the program name is, um, a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nAdditionally, we have a class chatroom at Slack where anyone in the class can ask questions and anyone can answer. I will monitor Slack regularly and will respond quickly. (It’s one of the rare Slack workspaces where I actually have notifications enabled!) Ask questions about the readings, assignments, and project. You’ll likely have similar questions as your peers, and you’ll likely be able to answer other peoples’ questions too."
  },
  {
    "objectID": "syllabus.html#course-structure",
    "href": "syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course structure",
    "text": "Course structure\nWe meet weekly from 4:30–7:00 PM on Mondays in 330 Aderhold. However, despite policies and rhetoric to the contrary, we’re still in the middle of a severe global pandemic, and the BA.5 variant of COVID-19 is raging.\nAccordingly, this semester we’re going to have a flipped classroom, which will let us maximize flexibility during this pandemic.\nWe will not have lectures during our regularly scheduled class time. Instead, you will do the readings and watch recorded lecture videos prior to each in-person class session. You can do the readings and watch the videos on your own schedule at whatever time works best for you. Many of you work full time and you have childcare and parental care responsibilities, leaving you with only evenings for coursework. I’ve designed this asynchronous system with you specifically in mind. I also can only really do teaching work at night when my kids are in bed—I recorded all these videos between like 10 PM and 2 AM. We’re all in similar pandemic boats.\nWe will do several things during our Monday in-person classes:\n\nExtensive Q&A: As you do the readings and watch the videos prior to class, you will inevitably have questions. In your weekly check-in assignment, you’ll submit (at least) 3 of those questions to me prior to class. We’ll spend a good chunk of each class answering, clarifying, debating, and discussing your questions.\nActivities: In some weeks, we’ll do some in-class activities to help solidify concepts about logic models, DAGs, and other evaluation and causal inference principles.\nR labs: We’ll spend a substantial time during each class learning and working with R together. You’ll need to bring a computer."
  },
  {
    "objectID": "syllabus.html#attendance-and-participation",
    "href": "syllabus.html#attendance-and-participation",
    "title": "Syllabus",
    "section": "Attendance and participation",
    "text": "Attendance and participation\nYou’re expected to come to class each Monday prepared—having read the material and watched the videos—and ready to discuss the content and work with R.\nAttendance and participation are important to your success in this course. However, again, we’re still in the middle of a global pandemic. If you are sick or are incapable of participating meaningfully in class (e.g. you have stayed up all night and are going to fall asleep in class), please stay home. I will stream our in-person sessions on Mondays via Webex (and will set up my own camera and microphone system to do it), so if you cannot attend, you can tune in if needed.\nGSU has some new process for getting absences excused because of illness, but I don’t care about that process. If you’re sick, I don’t need a doctor’s note or anything. If a relative dies and you have to attend a funeral, do it!—don’t worry about sending me confirmation or anything. If your childcare situation falls through one week, focus on your kids!—again, don’t worry about sending me confirmation. You’re all adults—I trust you. Given the flipped nature of the course, you’ll be able to catch up on the material.\nIf you test positive for COVID-19, report it at https://cc-gsu.force.com/s/, hunker down, and focus on getting better! Please do not come to class."
  },
  {
    "objectID": "syllabus.html#pandemic-stuff",
    "href": "syllabus.html#pandemic-stuff",
    "title": "Syllabus",
    "section": "Pandemic stuff",
    "text": "Pandemic stuff\n\nMasks and vaccines\nGSU does not require this and I can’t require this but I am allowed to urge it so here’s me urging it:Please get the COVID-19 vaccination and a booster shot (sign up for one here!). It is free. It saves lives. (I am fully vaccinated and boosted.)\nGSU and the University System of Georgia do not have a mask mandate for students or faculty. However, I personally will be wearing a mask when the CDC’s community transmission levels in the Atlanta area are medium or above.\nI strongly recommend/urge/encourage you to wear a mask in class on Mondays regardless of your vaccination status. I will place a box of disposable masks by the door if you would like one.\nAgain, GSU does not require either vaccines or masks, and if you aren’t vaccinated or don’t wear a mask, there are no penalties.\n\n\nLearning during a pandemic\nLife absolutely sucks right now. None of us is really okay. We’re all just pretending.\nYou most likely know people who have lost their jobs, have tested positive for COVID-19, have been hospitalized, or have even died (I myself know people in all those categories). You all have increased (or possibly decreased) work responsibilities and increased family care responsibilities—you might be caring for extra people (young and/or old!) right now, and you are likely facing uncertain job prospects (or have been laid off!).\nI’m fully committed to making sure that you learn everything you were hoping to learn from this class! I will make whatever accommodations I can to help you finish your problem sets, do well on your projects, and learn and understand the class material. Under ordinary conditions, I am flexible and lenient with grading and course expectations when students face difficult challenges. Under pandemic conditions, that flexibility and leniency is intensified.\nIf you tell me you’re having trouble, I will not judge you or think less of you. I hope you’ll extend me the same grace.\nYou never owe me personal information about your health (mental or physical). You are always welcome to talk to me about things that you’re going through, though. If I can’t help you, I usually know somebody who can.\nIf you need extra help, or if you need more time with something, or if you feel like you’re behind or not understanding everything, do not suffer in silence! Talk to me! I will work with you. I promise.\nPlease sign up for a time to meet with me during student hours at https://calendly.com/andrewheiss/. I’m also available through e-mail and Slack. I’ve enabled notifications on my Slack account, so I’ll see your messages quickly!\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\nBe nice. Be honest. Don’t cheat.\nWe will also follow Georgia State’s Code of Conduct.\nThis syllabus reflects a plan for the semester. Deviations may become necessary as the semester progresses.\n\nStudent hours\nPlease watch this video:\n\n\nStudent hours are set times dedicated to all of you (most professors call these “office hours”; I don’t).1 This means that I will be in my office at home (wistfully) waiting for you to come by talk to me remotely with whatever questions you have. This is the best and easiest way to find me and the best chance for discussing class material and concerns.\nBecause of the pandemic, it is easiest to meet with me online via Webex for student hours. Make an appointment with me here—the confirmation e-mail will contain a link for a Webex meeting. You can also find me through e-mail and Slack.\n\n\nLate work\nYou will lose 1 point per day for each day a problem set is late. This is designed to not be a huge penalty (3 days late = 27/30 points on a problem set that gets a ✓), but instead is a commitment device to help you stay on schedule.\n\n\nCounseling and Psychological Services (CPS)\nLife at GSU can be complicated and challenging (especially during a pandemic!). You might feel overwhelmed, experience anxiety or depression, or struggle with relationships or family responsibilities. Counseling and Psychological Services (CPS) provides free, confidential support for students who are struggling with mental health and emotional challenges. The CPS office is staffed by professional psychologists who are attuned to the needs of all types of college and professional students. Please do not hesitate to contact CPS for assistance—getting help is a smart and courageous thing to do.\n\n\nBasic needs security\nIf you have difficulty affording groceries or accessing sufficient food to eat every day, or if you lack a safe and stable place to live, and you believe this may affect your performance in this course, please contact the Dean of Students for support. They can provide a host of services including free groceries from the Panther Pantry and assisting with homelessness with the Embark Network. Additionally, please talk to me if you are comfortable in doing so. This will enable me to provide any resources that I might possess.\n\n\nLauren’s Promise\nI will listen and believe you if someone is threatening you.\nLauren McCluskey, a 21-year-old honors student athlete, was murdered on October 22, 2018 by a man she briefly dated on the University of Utah campus. We must all take action to ensure that this never happens again.\nIf you are in immediate danger, call 911 or GSU police (404-413-3333).\nIf you are experiencing sexual assault, domestic violence, or stalking, please report it to me and I will connect you to resources or call GSU’s Counseling and Psychological Services (404-413-1640).\nAny form of sexual harassment or violence will not be excused or tolerated at Georgia State. GSU has instituted procedures to respond to violations of these laws and standards, programs aimed at the prevention of such conduct, and intervention on behalf of the victims. Georgia State University Police officers will treat victims of sexual assault, domestic violence, and stalking with respect and dignity. Advocates on campus and in the community can help with victims’ physical and emotional health, reporting options, and academic concerns.\n\n\nAcademic honesty\nViolation of GSU’s Policy on Academic Honesty will result in an F in the course and possible disciplinary action.2 All violations will be formally reported to the Dean of Students.\n\n\nSpecial needs\nStudents who wish to request accommodation for a disability may do so by registering with the Office of Disability Services. Students may only be accommodated upon issuance by the Office of Disability Services of a signed Accommodation Plan and are responsible for providing a copy of that plan to instructors of all classes in which accommodations are sought.\nStudents with special needs should then make an appointment with me during the first week of class to discuss any accommodations that need to be made."
  },
  {
    "objectID": "syllabus.html#assignments-and-grades",
    "href": "syllabus.html#assignments-and-grades",
    "title": "Syllabus",
    "section": "Assignments and grades",
    "text": "Assignments and grades\nYou can find descriptions for all the assignments on the assignments page.\n\n\n\n\n\n\n\n\n\nAssignment\nPoints\nPercent\n\n\n\n\nWeekly check-ins (14 × 10)\n140\n15.1%\n\n\nProblem sets (9 × 30)\n270\n29.0%\n\n\nEvaluation assignments (4 × 30)\n120\n12.9%\n\n\nExam 1\n100\n10.8%\n\n\nExam 2\n100\n10.8%\n\n\nFinal project\n200\n21.5%\n\n\nTotal\n930\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nRange\nGrade\nRange\n\n\n\n\nA\n93–100%\nC\n73–76%\n\n\nA−\n90–92%\nC−\n70–72%\n\n\nB+\n87–89%\nD+\n67–69%\n\n\nB\n83–86%\nD\n63–66%\n\n\nB−\n80–82%\nD−\n60–62%\n\n\nC+\n77–79%\nF\n&lt; 60%"
  },
  {
    "objectID": "syllabus.html#star-wars",
    "href": "syllabus.html#star-wars",
    "title": "Syllabus",
    "section": "Star Wars",
    "text": "Star Wars\nOnce you have read this entire syllabus and the assignments page, please click here and e-mail me a picture of a cute Star Wars character.3 Brownie points if it’s animated."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere’s fairly widespread misunderstanding about what office hours actually are! Many students often think that they are the times I shouldn’t be disturbed, which is the exact opposite of what they’re for!↩︎\nSo seriously, just don’t cheat or plagiarize!↩︎\nBaby Yoda, Babu Frik, porgs, etc. are all super fair game.↩︎"
  },
  {
    "objectID": "resource/zilch.html#zilch",
    "href": "resource/zilch.html#zilch",
    "title": "Zilch and simulations",
    "section": "Zilch!",
    "text": "Zilch!\n\nRules\nRoll six dice. You must keep at least one scoring die every roll. You must get at least 500 points before stopping and keeping the total. If you do not get 500 points, you get zilch (0) that round and the next person rolls.\nAfter reaching 500 points, you can either stop, write down, and keep your score or continue to roll. As long as you can keep at least one scoring die, you can continue to roll and accumulate points. If you do not get a scoring combination in a roll, you lose all those points.\nIf you score with all six dice, you can pick them all up and continue rolling with them.\nWhoever reaches 10,000 points first wins.\n\n\nPoint system\n\n\n\n\n\n\n\n\n\nRoll\nPoints\n\n\n\n\nSingle dice\n\n\n\n100\n\n\n\n50\n\n\nThree of a kind (number × 100)\n\n\n  \n200\n\n\n  \n300\n\n\n  \n400\n\n\n  \n500\n\n\n  \n600\n\n\nSpecial rolls\n\n\n  \n1,000\n\n\n   \n2,000\n\n\nAny three pairs\ne.g.,      \n1,000\n\n\n5-die straight\n     or\n    \n1,750"
  },
  {
    "objectID": "resource/zilch.html#probability-with-math",
    "href": "resource/zilch.html#probability-with-math",
    "title": "Zilch and simulations",
    "section": "Probability with math",
    "text": "Probability with math\nYou can use probability math to calculate the chance of rolling at least a 1 or a 5 (so that you score something and can roll again). If you’re only rolling 1 die, the chance of rolling a 1 or a 5 is \\(\\frac{2}{6}\\), or \\(\\frac{1}{3}\\). When you start thinking about 2 dice, though, the math gets a little trickier because you care about rolling at least a 1 or 5, and there’s a chance you could roll both. So instead, we can calculate the probability of not rolling a 1 or a 5 and then subtract that from 1.\nWith 2 dice, the probability of not rolling a 1 or a 5 is \\(\\frac{4}{6}\\) or \\(\\frac{2}{3}\\) for each die. To calculate the joint probability, we can multiply each die’s probability:\n\\[\n\\begin{aligned}\n1 - (\\frac{2}{3} \\times \\frac{2}{3}) &= \\\\\n1 - \\frac{4}{9} &= 0.5\\overline{55}\n\\end{aligned}\n\\]\nThat means there’s a 55% chance of rolling at least a 1 or a 5 when rolling 2 dice. This approach scales up to any number of dice—multiply that \\(\\frac{2}{3}\\) for each die included. For instance, here’s 4 dice:\n\\[\n\\begin{aligned}\n1 - (\\frac{2}{3} \\times \\frac{2}{3} \\times \\frac{2}{3} \\times \\frac{2}{3}) &= \\\\\n1 - \\frac{16}{81} &= 0.80\n\\end{aligned}\n\\]\nWe can generalize this by using exponents, where \\(n\\) is the number of dice you’re rolling:\n\\[\n1 - \\frac{2^n}{3^n}\\quad \\text{ or }\\quad 1 - \\left(\\frac{2}{3}\\right)^n\n\\]"
  },
  {
    "objectID": "resource/zilch.html#probabilty-with-math-and-computers",
    "href": "resource/zilch.html#probabilty-with-math-and-computers",
    "title": "Zilch and simulations",
    "section": "Probabilty with math and computers",
    "text": "Probabilty with math and computers\nDoing that math by hand gets tedious, so we can put it in an R function and have R do the math for us.\n\nprob_1_or_5 &lt;- function(n) {\n  1 - (2/3)^n\n}\n\n# 1 die\nprob_1_or_5(1)\n## [1] 0.3333\n\n# 5 dice\nprob_1_or_5(5)\n## [1] 0.8683\n\n# 6 dice\nprob_1_or_5(6)\n## [1] 0.9122"
  },
  {
    "objectID": "resource/zilch.html#probability-with-computers-only",
    "href": "resource/zilch.html#probability-with-computers-only",
    "title": "Zilch and simulations",
    "section": "Probability with computers only",
    "text": "Probability with computers only\nInstead of figuring out the math behind the probability of getting at least a 1 or a 5, we can simulate a bunch of dice rolls and brute force our way to the answer. Here’s the general process:\n\nRoll 6 dice 100,000 times (or whatever number you want)\nCount how many times a 1 or a 5 appears in a roll\nDivide that count by 100,000. That’s the probability.\n\nProbably the most intiuitive (though not necessarily computationally efficient) way to do with with R is to use a for loop. In R, a for loop will will repeat some chunk of repeatedly until some condition is met, and that condition is generally tracked with an index variable that is specific to the inside of the loop. For instance, this loop uses an index variable named i. It will set i to 1 the first time it runs the loop and then do whatever’s inside (print(...) in this case). When it finishes the inside code, it’ll bump i up to the next number (2 here) and run the inside code again, and again, and again until it reaches the end of the index range (4 here):\n\nfor (i in 1:4) {\n  print(paste(\"Loop number\", i))\n}\n## [1] \"Loop number 1\"\n## [1] \"Loop number 2\"\n## [1] \"Loop number 3\"\n## [1] \"Loop number 4\"\n\nTo make this work with our dice simulation, we need to add one more component. We want to store the results of each loop run in a variable that we can use later. The most efficient way to do this is to create an empty variable first that has enough slots in it to contain the output, then add to that variable while going through the loop:\n\n# This is \"logical\" because it's only going to hold TRUE and FALSE values. If we\n# wanted to put numbers in it, we'd need to use \"double\"; if we wanted to put\n# text in it, we'd need to use \"character\"\noutput &lt;- vector(\"logical\", 4)\n\nfor (i in 1:4) {\n  # Check if i is 3 and store the result in the ith slot\n  output[[i]] &lt;- i == 3\n}\n\noutput\n## [1] FALSE FALSE  TRUE FALSE\n\nLet’s build a loop now that rolls 6 dice, checks for a 1 or a 5, and stores the result. We’ll use 100,000 times for fun.\n\n# Create empty variable with enough slots\nhas_1_or_5 &lt;- vector(\"logical\", 100000)\n\n# Roll a bunch of dice a bunch of times\nfor (i in 1:100000) {\n  # Roll some dice\n  rolled_dice &lt;- sample(1:6, 6, replace = TRUE)\n  \n  # Check if there's a 1 or a 5 in there\n  did_it_happen &lt;- 1 %in% rolled_dice | 5 %in% rolled_dice\n  \n  # Store the result  \n  has_1_or_5[i] &lt;- did_it_happen\n}\n\n# Find the proportion of TRUEs\nsum(has_1_or_5) / 100000\n## [1] 0.9122\n\nOut of the 100,000 rolls, 91,220 of them had a 1 or a 5 in them, meaning that there’s a 91.22% chance of scoring something on an initial roll in Zilch.\nHow does that compare to the official math?\n\\[\n1 - \\left( \\frac{2}{3} \\right)^6\n\\]\n\nprob_1_or_5(6)\n## [1] 0.9122\n\nIt’s basically the same! But we found the answer without doing any actual probability math, which is neat.\nWe can generalize this simulation a little more by not hardcoding some of the parameters. We can make it so both the number of dice to roll and the number of simulations are adjustable by sticking this in a function. For example, here’s 4 dice 50,000 times:\n\nsimulate_zilch &lt;- function(n_dice, n_sims) {\n  # Create empty variable with enough slots\n  has_1_or_5 &lt;- vector(\"logical\", n_sims)\n  \n  # Roll a bunch of dice a bunch of times\n  for (i in 1:n_sims) {\n    # Roll some dice\n    rolled_dice &lt;- sample(1:6, n_dice, replace = TRUE)\n    \n    # Check if there's a 1 or a 5 in there\n    did_it_happen &lt;- 1 %in% rolled_dice | 5 %in% rolled_dice\n    \n    # Store the result  \n    has_1_or_5[i] &lt;- did_it_happen\n  }\n  \n  # Find the proportion of TRUEs\n  sum(has_1_or_5) / n_sims\n}\n\nsimulate_zilch(n_dice = 4, n_sims = 50000)\n## [1] 0.8027"
  },
  {
    "objectID": "resource/zilch.html#why-even-do-this",
    "href": "resource/zilch.html#why-even-do-this",
    "title": "Zilch and simulations",
    "section": "Why even do this?",
    "text": "Why even do this?\nBut we know the probability equation for getting at least a 1 or a 5, so why go through the hassle of making the computer roll millions of dice? Because we’re not actually calculating the true probability of scoring every valid scoring combination!\nIn Zilch, you can score with at least a 1 or a 5, but you can also score with three-of-a-kind or three pairs or a 5-die straight. We could calculate the probability of rolling those and combine them with the probability of a 1 or a 5, but the formal equation will get really hairy and complicated. So instead, we can simulate.\n\nsimulate_zilch_full &lt;- function(n_dice, n_sims) {\n  # Create empty variable with enough slots\n  did_something_score &lt;- vector(\"logical\", n_sims)\n  \n  # Roll a bunch of dice a bunch of times\n  for (i in 1:n_sims) {\n    # Roll some dice\n    rolled_dice &lt;- sample(1:6, n_dice, replace = TRUE)\n\n    # Check for 3 pairs separately since it's a complicated process\n    # If there are three different numbers...\n    if (length(table(rolled_dice)) == 3) {\n      # ...check if there are 3 pairs\n      three_pairs &lt;- all(table(rolled_dice) == c(2, 2, 2))\n    } else {\n      three_pairs &lt;- FALSE\n    }\n    \n    # Check if there's a scoring combination in there\n    did_it_happen &lt;- 1 %in% rolled_dice |  # A 1\n      5 %in% rolled_dice |  # A 5\n      all(1:5 %in% rolled_dice) |  # A 1-5 straight\n      all(2:6 %in% rolled_dice) |  # A 2-6 straight\n      max(table(rolled_dice)) &gt;= 3 |  # At least 3 of one number\n      three_pairs  # 3 pairs\n\n    # Store the result\n    did_something_score[i] &lt;- did_it_happen\n  }\n  \n  # Find the proportion of TRUEs\n  sum(did_something_score) / n_sims\n}\n\nsix_dice &lt;- simulate_zilch_full(6, 50000)\n\nPhew! Now that we account for every possible scoring combination, there’s a 97.69% chance of scoring something when rolling 6 dice. That’s really high!\nFor fun, let’s look at how that probability changes as the number of dice you roll decreases:\n\nlibrary(tidyverse)\n\n# hoooo boy this is slow\nnumber_of_dice &lt;- tibble(n_dice = 6:1) %&gt;% \n  mutate(prob = map_dbl(n_dice, ~simulate_zilch_full(., 50000)))\n\n\nggplot(number_of_dice, aes(x = fct_rev(factor(n_dice)), y = prob)) +\n  geom_col() +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x = \"Number of dice rolled\", y = \"Probability of scoring something\",\n       caption = \"Results over 50,000 simulations per count of dice\") +\n  theme_minimal()"
  },
  {
    "objectID": "resource/style.html",
    "href": "resource/style.html",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg %&gt;% \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg %&gt;% filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg %&gt;% \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times."
  },
  {
    "objectID": "resource/style.html#r-style-conventions",
    "href": "resource/style.html#r-style-conventions",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg %&gt;% \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% filter(cty &gt; 10, class == \"compact\")\n\nmpg %&gt;% \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg %&gt;% filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg %&gt;% \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times."
  },
  {
    "objectID": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "href": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "title": "R style suggestions",
    "section": "Main style things to pay attention to for this class",
    "text": "Main style things to pay attention to for this class\n\nImportant note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty&gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n\n\nSpacing\n\nSee the “Spacing” section in the tidyverse style guide.\n\nPut spaces after commas (like in regular English):\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg , cty &gt; 10)\nfilter(mpg ,cty &gt; 10)\nfilter(mpg,cty &gt; 10)\n\nPut spaces around operators like +, -, &gt;, =, etc.:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter(mpg, cty&gt;10)\nfilter(mpg, cty&gt; 10)\nfilter(mpg, cty &gt;10)\n\nDon’t put spaces around parentheses that are parts of functions:\n\n# Good\nfilter(mpg, cty &gt; 10)\n\n# Bad\nfilter (mpg, cty &gt; 10)\nfilter ( mpg, cty &gt; 10)\nfilter( mpg, cty &gt; 10 )\n\n\n\nLong lines\n\nSee the “Long lines” section in the tidyverse style guide.\n\nIt’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” &gt; “Global Options” &gt; “Code” &gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n\n# Good\nfilter(mpg, cty &gt; 10, class == \"compact\")\n\n# Good\nfilter(mpg, cty &gt; 10, \n       class == \"compact\")\n\n# Good\nfilter(mpg,\n       cty &gt; 10,\n       class == \"compact\")\n\n# Bad\nfilter(mpg, cty &gt; 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n# Good\nfilter(mpg, \n       cty &gt; 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\nPipes (%&gt;%) and ggplot layers (+)\nPut each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n\n# Good\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n# Bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n# Super bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n# Super bad and won't even work\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\nPut each step in a dplyr pipeline on separate lines, with the %&gt;% at the end of the line, indented with two spaces:\n\n# Good\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;% \n  group_by(class) %&gt;% \n  summarize(avg_hwy = mean(hwy))\n\n# Bad\nmpg %&gt;% filter(cty &gt; 10) %&gt;% group_by(class) %&gt;% \n  summarize(avg_hwy = mean(hwy))\n\n# Super bad\nmpg %&gt;% filter(cty &gt; 10) %&gt;% group_by(class) %&gt;% summarize(avg_hwy = mean(hwy))\n\n# Super bad and won't even work\nmpg %&gt;% \n  filter(cty &gt; 10)\n  %&gt;% group_by(class)\n  %&gt;% summarize(avg_hwy = mean(hwy))\n\n\n\nComments\n\nSee the “Comments” section in the tidyverse style guide.\n\nComments should start with a comment symbol and a single space: #\n\n# Good\n\n#Bad\n\n    #Bad\n\nIf the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\n\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%  # Only rows where cty is 10 +\n  group_by(class) %&gt;%  # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nYou can add extra spaces to get inline comments to align, if you want:\n\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%            # Only rows where cty is 10 +\n  group_by(class) %&gt;%             # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nIf the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” &gt; “Reflow comment”\n\n# Good\n# Happy families are all alike; every unhappy family is unhappy in its own way.\n# Everything was in confusion in the Oblonskys’ house. The wife had discovered\n# that the husband was carrying on an intrigue with a French girl, who had been\n# a governess in their family, and she had announced to her husband that she\n# could not go on living in the same house with him. This position of affairs\n# had now lasted three days, and not only the husband and wife themselves, but\n# all the members of their family and household, were painfully conscious of it.\n\n# Bad\n# Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n\nThough, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose."
  },
  {
    "objectID": "resource/r.html",
    "href": "resource/r.html",
    "title": "R",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio."
  },
  {
    "objectID": "resource/r.html#learning-r",
    "href": "resource/r.html#learning-r",
    "title": "R",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio."
  },
  {
    "objectID": "resource/r.html#r-in-the-wild",
    "href": "resource/r.html#r-in-the-wild",
    "title": "R",
    "section": "R in the wild",
    "text": "R in the wild\nA popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish knitted HTML files directly to RPubs, but you can also post your output to a blog or other type of website.1 Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\nHere are some of the best examples I’ve come across:\n\nText analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up)\nBob Ross - Joy of Painting\nBechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight.\nSexism on the Silver Screen: Exploring film’s gender divide\nComparison of Quentin Tarantino Movies by Box Office and the Bechdel Test\nWho came to vote in Utah’s caucuses?\nHealth care indicators in Utah counties\nSong lyrics across the United States\nA decade (ish) of listening to Sigur Rós\nWhen is Tom peeping these days?: There are a also bunch of final projects from other R and data visualization classes here and here.\nMapping Fall Foliage\nGeneral (Attys) Distributions\nDisproving Approval"
  },
  {
    "objectID": "resource/r.html#footnotes",
    "href": "resource/r.html#footnotes",
    "title": "R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you want to be really fancy, you can use blogdown, which makes a complete website with R Markdown files. That’s actually how this site is built (see the source code). You can build your own site with this tutorial.↩︎"
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "",
    "text": "You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code."
  },
  {
    "objectID": "resource/install.html#rstudio.cloud",
    "href": "resource/install.html#rstudio.cloud",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "RStudio.cloud",
    "text": "RStudio.cloud\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://rstudio.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you."
  },
  {
    "objectID": "resource/install.html#rstudio-on-your-computer",
    "href": "resource/install.html#rstudio-on-your-computer",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "RStudio on your computer",
    "text": "RStudio on your computer\nRStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\n\nInstall R\nFirst you need to install R itself (the engine).\n\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\n\n\n\n\n\n\n\n\n\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is 4.2.1) and download it.\n\n\n\n\n\n\n\n\n\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\n\n\n\n\n\n\n\n\n\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n\n\n\n\n\n\n\n\n\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\n\n\n\n\n\n\n\n\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\n\n\n\n\n\n\n\n\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall tinytex\nWhen you knit to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nHere’s how to install tinytex so you can knit to pretty PDFs:\n\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console.\nRun tinytex::install_tinytex() in the console.\nWait for a bit while R downloads and installs everything you need.\nThe end! You should now be able to knit to PDF."
  },
  {
    "objectID": "resource/install.html#footnotes",
    "href": "resource/install.html#footnotes",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt’s a goofy name, but CRAN is where most R packages—and R itself—lives.↩︎"
  },
  {
    "objectID": "resource/exam2.html",
    "href": "resource/exam2.html",
    "title": "Things you should know for Exam 2",
    "section": "",
    "text": "Understand why randomization is crucial for causal inference and counterfactuals\nUnderstand the process for analyzing a randomized controlled trial\n\nCrucial resources:\n\nReadings, slides, and videos for randomization and matching\nGuide for RCTs\nProblem set 3\nTask 1 in problem set 8"
  },
  {
    "objectID": "resource/exam2.html#randomization",
    "href": "resource/exam2.html#randomization",
    "title": "Things you should know for Exam 2",
    "section": "",
    "text": "Understand why randomization is crucial for causal inference and counterfactuals\nUnderstand the process for analyzing a randomized controlled trial\n\nCrucial resources:\n\nReadings, slides, and videos for randomization and matching\nGuide for RCTs\nProblem set 3\nTask 1 in problem set 8"
  },
  {
    "objectID": "resource/exam2.html#matching-and-inverse-probability-weighting",
    "href": "resource/exam2.html#matching-and-inverse-probability-weighting",
    "title": "Things you should know for Exam 2",
    "section": "Matching and inverse probability weighting",
    "text": "Matching and inverse probability weighting\n\nUnderstand the intuition behind matching and inverse probability weighting\nUnderstand the process for adjusting for confounders and closing backdoors with both matching and inverse probability weighting\n\nCrucial resources:\n\nReadings, slides, and videos for randomization and matching\nGuide for matching and inverse probability weighting\nProblem set 3\nTask 2 in problem set 8"
  },
  {
    "objectID": "resource/exam2.html#difference-in-difference",
    "href": "resource/exam2.html#difference-in-difference",
    "title": "Things you should know for Exam 2",
    "section": "Difference-in-difference",
    "text": "Difference-in-difference\n\nUnderstand the intuition behind making causal inferences with difference-in-differences\nUnderstand the process for analyzing diff-in-diffs\n\nCrucial resources:\n\nReadings, slides, and videos for diff-in-diff\nGuide for diff-in-diff\nProblem set 4\nProblem set 5\nTask 3 in problem set 8"
  },
  {
    "objectID": "resource/exam2.html#regression-discontinuity",
    "href": "resource/exam2.html#regression-discontinuity",
    "title": "Things you should know for Exam 2",
    "section": "Regression discontinuity",
    "text": "Regression discontinuity\n\nUnderstand the intuition behind making causal inferences with regression discontinuity\nUnderstand the process for analyzing regression discontinuities, both fuzzy and sharp\nUnderstand the difference between ATE and LATE\n\nCrucial resources:\n\nReadings, slides, and videos for regression discontinuity I (sharp)\nReadings, slides, and videos for regression discontinuity II (fuzzy)\nGuide for sharp diff-in-diff\nGuide for fuzzy diff-in-diff\nProblem set 6\nTask 4 in problem set 8"
  },
  {
    "objectID": "resource/exam2.html#instrumental-variables",
    "href": "resource/exam2.html#instrumental-variables",
    "title": "Things you should know for Exam 2",
    "section": "Instrumental variables",
    "text": "Instrumental variables\n\nUnderstand the intuition behind using instruments for causal inference\nUnderstand the three characteristics of a good instrument\nUnderstand the process for analyzing data with instrumental variables and 2SLS\nUnderstand the difference between ATE and LATE\n\nCrucial resources:\n\nReadings, slides, and videos for instrumental variables I\nReadings, slides, and videos for instrumental variables II\nGuide for instrumental variables\nProblem set 7\nTask 5 in problem set 8"
  },
  {
    "objectID": "resource/data.html",
    "href": "resource/data.html",
    "title": "Data",
    "section": "",
    "text": "There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n\nData is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\nGoogle Dataset Search: Google indexes thousands of public datasets; search for them here.\nKaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\nUS City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\nPolitical science and economics datasets: There’s a wealth of data available for political science- and economics-related topics:\n\nFrançois Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities.\nThomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.).\nErik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)"
  },
  {
    "objectID": "resource/bayes.html",
    "href": "resource/bayes.html",
    "title": "Bayesian statistics resources",
    "section": "",
    "text": "In class session 2 (see this from the FAQ slides) we talked briefly about the difference between frequentist statistics, where you test for the probability of your data given a null hypothesis, or \\(P(\\text{data} \\mid H_0)\\), and Bayesian statistics, where you test for the probability of your hypothesis given your data, or \\(P(H \\mid \\text{data})\\).\nThis difference is important. In the world of frequentism and null hypothesis significance testing (NHST), which is what pretty much all statistics classes use (including this one!), you have to compare your findings to a hypothetical null world and you have to talk about rejecting null hypotheses. In the Bayes world, though, you get to talk about the probability that your hypothesis is correct rather than the probability of seeing a value in a null world. So much more convenient and easy to interpret!\nBayesian statistics, though, requires a lot of computational power and a different way of thinking about statistics and numbers in general. And very few classes teach it. Including this one! I use Bayesian stats all the time in my own research (see this or this, for instance), but don’t teach it (yet!) because nobody else really teaches it and frequentist statistics still rule the policy world, so you need to know it."
  },
  {
    "objectID": "resource/bayes.html#resources",
    "href": "resource/bayes.html#resources",
    "title": "Bayesian statistics resources",
    "section": "Resources",
    "text": "Resources\nBut you can learn it on your own. Because very few stats classes actually teach Bayesian statistics, tons of people who use it are self-taught (like me!), in part because there are a ton of resources online for learning this stuff. Here are some of the best I’ve found:\n\nThis new Bayes Rules book is designed to be an introductory textbook for a stats class teaching Bayesian stuff. It’s really accessible and good (and free!). If I ever get to teach an intro stats class with Bayesian stats, I’ll use this.\nThis post from 2016 is a great short introduction and is what made me start using Bayesian methods. The brms package makes it incredibly easy to do Bayesian stuff, and the syntax is basically the same as lm()\nThis post shows how to do one simple task (a difference-in-means test) with regular old frequentist methods, bootstrapping, and with Bayesian stats both with brms and raw Stan code\nThis short post gives a helpful overview of the intuition behind Bayesianism\nThe super canonical everyone-has-this-book book is Statistical Rethinking by Richard McElreath. At that page he also has an entire set of accompanying lectures on YouTube. He doesn’t use brms or ggplot, but someone has translated all his models to tidyverse-based brms code here\nThe Theory That Would Not Die is a fun little general introduction to the history of Bayesianism and why it kind of disappeared in the 20th century and was replaced by frequentism and p-values and null hypothesis testing"
  },
  {
    "objectID": "resource/bayes.html#super-short-example",
    "href": "resource/bayes.html#super-short-example",
    "title": "Bayesian statistics resources",
    "section": "Super short example",
    "text": "Super short example\nIn practice, the R code for Bayesian models should be very familiar. For instance, here’s a regular old frequentist OLS model:\n\n\nCode\nlibrary(tidyverse)\nlibrary(broom)\n\nmodel_ols &lt;- lm(hwy ~ displ + drv, data = mpg)\ntidy(model_ols, conf.int = TRUE)\n## # A tibble: 4 × 7\n##   term        estimate std.error statistic  p.value conf.low conf.high\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)    30.8      0.924     33.4  4.21e-90    29.0      32.6 \n## 2 displ          -2.91     0.218    -13.4  1.73e-30    -3.34     -2.48\n## 3 drvf            4.79     0.530      9.05 6.40e-17     3.75      5.83\n## 4 drvr            5.26     0.734      7.17 1.03e-11     3.81      6.70\n\n\nHere’s that same model using the brms package, with default priors. Note how the code is basically the same:\n\n\nCode\nlibrary(tidyverse)\nlibrary(brms)         # For Bayesian regression with brm()\nlibrary(broom.mixed)  # For tidy() and glance() with brms-based models\nlibrary(tidybayes)    # For extracting posterior draws\n\n\n\n\nCode\n# This will take a few seconds to run\nmodel_bayes &lt;- brm(hwy ~ displ + drv, data = mpg)\n\n\n\n\nCode\ntidy(model_bayes)\n## # A tibble: 5 × 8\n##   effect   component group    term            estimate std.error conf.low conf.high\n##   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 fixed    cond      &lt;NA&gt;     (Intercept)        30.8      0.945    29.0      32.7 \n## 2 fixed    disp      &lt;NA&gt;     displ              -2.91     0.220    -3.34     -2.49\n## 3 fixed    cond      &lt;NA&gt;     drvf                4.79     0.543     3.73      5.84\n## 4 fixed    cond      &lt;NA&gt;     drvr                5.27     0.733     3.84      6.69\n## 5 ran_pars cond      Residual sd__Observation     3.09     0.147     2.82      3.40\n\n\nIn Bayes land, you get a distribution of plausible values given the data (or what is called the “posterior distribution”), and you can visualize this posterior distribution:\n\n\nCode\n# Make a long dataset of the draws for these three coefficients\nposterior_draws &lt;- model_bayes %&gt;% \n  gather_draws(c(b_displ, b_drv, b_drvf, b_drvr))\n\n# Plot this thing\nggplot(posterior_draws, aes(x = .value, y = fct_rev(.variable), fill = .variable)) +\n  geom_vline(xintercept = 0) +\n  stat_halfeye(.width = c(0.8, 0.95), alpha = 0.8, point_interval = \"median_hdi\") +\n  guides(fill = \"none\") +\n  labs(x = \"Coefficient\", y = \"Variable\",\n       caption = \"80% and 95% credible intervals shown in black\")\n\n\n\n\n\n\n\n\n\nThose are all the plausible values for these coefficients, given the data that we’ve fed the model, and the black bars at the bottom show the 80% and 95% credible intervals (or the range of values that 80/95% of the posterior covers). With this, there’s a 95% chance that the coefficient for displacement is between −3.35 and −2.48. Neat!"
  },
  {
    "objectID": "resource/bayes.html#confidence-intervals-vs.-credible-intervals",
    "href": "resource/bayes.html#confidence-intervals-vs.-credible-intervals",
    "title": "Bayesian statistics resources",
    "section": "Confidence intervals vs. credible intervals",
    "text": "Confidence intervals vs. credible intervals\nIn session 6, we talked about frequentist confidence intervals and Bayesian credible (or posterior) intervals, since I had you read Guido Imbens’s essay on p-values, where his conclusion is that:\n\nIt would be preferable if reporting standards emphasized confidence intervals or standard errors, and, even better, Bayesian posterior intervals.\n\nImbens wants us to use Bayesian posterior intervals (or credible intervals), but how do we do that?\n\nFrequentist confidence intervals\nIn frequentist statistics (i.e. all the statistics you’ve been exposed to in this class and all previous classes), your whole goal is to estimate and infer something about a population using a sample. This “something” is a true (but unknown) thing called a population parameter. It is a single fixed value that exists out in the world, and it’s the main thing you’re interested in discovering. Here are a bunch of different population parameters:\n\nAverage treatment effect of a program\nProportion of left-handed students at GSU\nMedian rent of apartments in NYC\nProportion of red M&Ms produced in a factory\n\nIn frequentist statistics, we take a sample from the population, calculate the parameter (i.e. mean, median, proportion, whatever) in the sample, and then check to see how good of a guess it might be for the whole population. To do that, we can look at a confidence interval. Think of a confidence interval as a net—it’s a range of possible values for the population parameters, and we can be X% confident (typically 95%) that the net is picking up the population parameter. Another way to think about it is to imagine taking more samples. If you take 100 samples, at least 95 of them would have the true population parameter in their 95% confidence intervals. Frequentist statistics assumes that the unknown population parameter is fixed and singular, but that the data can vary—you can repeat an experiment over and over again, or take repeated samples from a population in order to be more certain about the estimate of the parameter (and shrink the net of the confidence interval).\nImportantly, when talking about confidence intervals, you cannot really say anything about the estimate of the parameter itself. Confidence intervals are all about the net, or the range itself. You can legally say this:\n\nWe are 95% confident that this confidence interval captures the true population parameter.\n\nYou cannot say this:\n\nThere’s a 95% chance that the population parameter is X. or There’s a 95% chance that the true value falls in this range.\n\nConfidence intervals tell you about the range, or the net. That’s all.\nHere’s an example with some data from The Effect on restaurant inspections in Alaska. We want to know if weekend inspections are more lenient that ones conducted during the work week.\n\n\nCode\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(gghalves)\n\ninspections &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/restaurant_inspections.csv\")\n\n\nFirst we should look at the data to see if there are any obvious patterns. Let’s look at scores separated by weekend status. We’ll use the neat gghalves package to plot both the raw points and a density plot. The orange points show the average value:\n\n\nCode\nggplot(inspections, aes(x = Weekend, y = inspection_score)) +\n  geom_half_point(side = \"l\", alpha = 0.2, size = 0.5,\n                  transformation = position_jitter(height = 0)) +\n  geom_half_violin(side = \"r\") +\n  stat_summary(fun.data = \"mean_se\", fun.args = list(mult = 1.96), color = \"orange\")\n\n\n\n\n\n\n\n\n\nIt looks like weekend inspections are far more rare than weekday ones, and no weekend inspections every give scores lower than 80. It also looks like the average weekend score is slightly higher than the average weekday score. Let’s figure out how much of a difference there is.\nBut first, we’ll use the language of inference and sampling. Our population parameter (we’ll call it the Greek letter theta, or \\(\\theta\\)) is some single true fixed number that exists out in the world—weekend restaurant inspections in Alaska have a \\(\\theta\\) higher average score than weekday inspections. We want to find out what that \\(\\theta\\) is, so we’ll look at some confidence intervals.\nWe can look at a basic difference in means based on weekend status:\n\n\nCode\nmodel_naive &lt;- lm(inspection_score ~ Weekend, \n                  data = inspections)\ntidy(model_naive, conf.int = TRUE)\n## # A tibble: 2 × 7\n##   term        estimate std.error statistic    p.value conf.low conf.high\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)    93.6     0.0381   2458.   0             93.6      93.7 \n## 2 WeekendTRUE     2.10    0.433       4.84 0.00000131     1.25      2.95\n\n\nHere, weekend scores are 2.1 points higher than weekday scores, on average (that’s our estimate, or \\(\\hat{\\theta}\\). We have a confidence interval of 1.2–2.9. We cannot say that we’re 95% confident that the weekend score boost (or \\(\\theta\\)) is between 1.2 and 2.9. What we can say is that we’re 95% confident that the range 1.2–2.9 captures the true population parameter \\(\\theta\\). If we took a bunch of different samples of inspection scores and calculated the average weekend vs. weekday score in each of those samples, 95% of those confidence intervals should capture the true \\(\\theta\\). Importantly, we still have no idea what the actual \\(\\theta\\) is, but we’re pretty sure that our confidence interval net has captured it.\nThis estimate is probably wrong, since there are other factors that confound the weekend → score relationship. Maybe the health department only conducts weekend inspections in places with lots of branches, or maybe they did more weekend inspections in certain years. We can adjust/control for these in the model:\n\n\nCode\nmodel_adjusted &lt;- lm(inspection_score ~ Weekend + NumberofLocations + Year, \n                     data = inspections)\ntidy(model_adjusted, conf.int = TRUE)\n## # A tibble: 4 × 7\n##   term              estimate std.error statistic  p.value conf.low conf.high\n##   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)       225.     12.4          18.1  7.88e-73 200.      249.    \n## 2 WeekendTRUE         1.43    0.419         3.42 6.25e- 4   0.611     2.25  \n## 3 NumberofLocations  -0.0191  0.000436    -43.9  0         -0.0200   -0.0183\n## 4 Year               -0.0646  0.00617     -10.5  1.45e-25  -0.0767   -0.0525\n\n\nOur weekend estimate shrunk a little and is now 1.43, with a confidence interval of 0.6–2.3. Again, think of this as a net—we’re 95% sure that the true \\(\\theta\\) is in that net somewhere. \\(\\theta\\) could be 0.7, it could be 1.4, it could be 2.2—who knows. All we know is that our net most likely picked it up.\nFor fun, let’s plot both these weekend estimates and their confidence intervals:\n\n\nCode\n# Save just the weekend coefficient from both models\nfreq_results_naive &lt;- tidy(model_naive, conf.int = TRUE) %&gt;% \n  mutate(model = \"Naive model\") %&gt;% \n  filter(term == \"WeekendTRUE\")\n\nfreq_results_full &lt;- tidy(model_adjusted, conf.int = TRUE) %&gt;% \n  mutate(model = \"Full model\") %&gt;% \n  filter(term == \"WeekendTRUE\")\n\n# Put these coefficients in a single dataset and plot them\nfreq_results &lt;- bind_rows(freq_results_naive, freq_results_full) %&gt;% \n  # Make sure the model name follows the order it appears in the data instead of\n  # alphabetical order\n  mutate(model = fct_inorder(model))\n\nggplot(freq_results, aes(x = estimate, y = model, color = model)) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) +\n  guides(color = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nBayesian credible intervals\nRemember, with frequentist statistics, \\(\\theta\\) is fixed and singular and we’re hoping to pick it up with our confidence interval nets. The data we collect is variable—we can hypothetically take more and more samples and calculate a bunch of confidence intervals and become more certain about where \\(\\theta\\) might be. We can only interpret confidence intervals as ranges: “There’s a 95% probability that the range contains the true value \\(\\theta\\)”. We can’t say anything about the estimate of \\(\\theta\\) itself. We’ve calculated the probability of the range, not the probability of the actual value.\nBayesian analysis, however, does let us talk about the probability of the actual value. Under Bayesianism, the data you’re working with is fixed (i.e. you collected it once and it’s all you have—you can’t go out and collect infinite additional samples), and the population parameter \\(\\theta\\) varies and has uncertainty about it (i.e. instead of imagining some single number uncapturable that’s the average difference in weekend vs. weekday scores, \\(\\theta\\) has some range around it).\nThis difference is apparent in the formulas for testing hypotheses under each of these approaches:\n\\[\\underbrace{P(\\text{Data} \\mid \\theta)}_{\\substack{\\textbf{Frequentism} \\\\ \\text{Probability of seeing the} \\\\ \\text{data given that } \\theta \\text{ exists}}} \\qquad \\underbrace{P(\\theta \\mid \\text{Data})}_{\\substack{\\textbf{Bayesianism} \\\\ \\text{Probability of } \\theta \\\\ \\text{given the current data}}}\\]\nBayes’ theorem has a nice formula (with neat intuition, like in this video):\n\\[\n\\underbrace{P(\\theta \\mid \\text{Data})}_{\\text{Posterior}} = \\frac{\\overbrace{P(\\theta)}^{\\text{Prior}} \\times \\overbrace{P(\\text{Data} \\mid \\theta)}^{\\text{Likelihood}}}{P(\\text{Data})}\n\\]\nPut (hopefully!) simply, combine the observed likelihood of the data \\(P(\\text{Data} \\mid \\theta)\\) (that’s basically frequentism!) with prior knowledge about the distribution of \\(\\theta\\) and you’ll get a posterior estimate of \\(\\theta\\).\nActually calculating this with real data, though, can be tricky and computationally intensive—often there’s no formal mathematical way to figure out the actual equation. So instead, we can use computers to simulate thousands of guesses and then look at the distribution of those guesses (just like we did with the Zilch simulation in class). One modern method for doing this is called Monte Carlo Markov Chain (MCMC) simulation, which is what most R-based tools for Bayesian stats use nowadays.\nLet’s look at restaurant inspection scores on the weekend Bayesianly. Here, we’re still interested in our population parameter \\(\\theta\\), or the average weekend score boost. Only now, we’re not assuming that \\(\\theta\\) is some single fixed value out in the world that we’re trying to capture with confidence intervals—we’ll use the data that we have to estimate the variation in \\(\\theta\\). The easiest way to do Bayesian analysis with R is with the brms package, which uses the familiar formula syntax you’ve been using with lm(). The syntax is super similar, just with a few additional arguments:\nMCMC things\nArguments like chains, iter, and cores deal with the simulation. chains defines how many parallel simulations should happen, iter controls how many iterations should happen with in each chain, and cores spreads those chains across the CPUs in your computer (i.e. if you have a 4-core computer, you can run 4 chains all at the same time; run parallel::detectCores() in your R console to see how many CPU cores you have). seed makes it so that the random simulation results are reproducible (see here for more on seeds).\nPriors\nThese define your prior beliefs about the parameters (i.e. \\(\\theta\\)) in the model. If you think that the restaurant weekend inspection boost is probably positive, but could possibly be negative, or maybe zero, you can feed that belief into the model. For instance, if you’re fairly confident (based on experiences in other states maybe) that weekend scores really are higher, you can provide an informative prior that says that \\(\\theta\\) is most likely 1.5 points ± a little variation, following a normal distribution. Or, if you have no idea what it could be—maybe it’s super high like 10, maybe it’s negative like −5, or maybe it’s 0 and there’s no weekend boost—you can provide a vague prior that says that \\(\\theta\\) is 0 points ± a ton of variation.\n\n\nCode\nlibrary(patchwork)  # For combining ggplot plots\n\nplot_informative &lt;- ggplot() +\n  stat_function(fun = dnorm, args = list(mean = 1.5, sd = 0.5),\n                geom = \"area\", fill = \"grey80\", color = \"black\") +\n  xlim(-1, 4) +\n  labs(title = \"Informative prior\", subtitle = \"Normal(mean = 1.5, sd = 0.5)\",\n       caption = \"We're pretty sure θ is around 1.5\")\n\nplot_vague &lt;- ggplot() +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 10),\n                geom = \"area\", fill = \"grey80\", color = \"black\") +\n  xlim(-35, 35) +\n  labs(title = \"Vague prior\", subtitle = \"Normal(mean = 0, sd = 10)\",\n       caption = \"Surely θ is in there *somewhere*\")\n\nplot_informative | plot_vague\n\n\n\n\n\n\n\n\n\nFor the sake of this example, we’ll use a vague prior.\nHere’s how to officially do Bayesian analysis with brms and incorporate prior information about \\(\\theta\\). Again, the syntax is super similar to lm(), just with some extra bits about the prior and the MCMC settings:\n\n\nCode\nlibrary(brms)         # For Bayesian regression with brm()\nlibrary(broom.mixed)  # For tidy() and glance() with brms-based models\nlibrary(tidybayes)    # For extracting posterior draws\nlibrary(ggdist)       # For making pretty posterior plots\n\n\n\n\nCode\n# bf() stands for \"bayes formula\"; you technically don't need to use it, but it \n# makes life easier for more complex models, so it's good practice even when \n# using a simple formula like the one here\n#\n# This will take a little bit of time to run. Here's what it's actually doing:\n#\n# 1. Translate this R code to Stan (a specific language for doing Bayesian stuff with MCMC)\n# 2. Compile the Stan code to faster-running C++ code\n# 3. Actually do the MCMC sampling\n\n# Set the prior for the weekend coefficient\n# Use get_priors() to see all the other default priors\npriors &lt;- c(\n  prior(normal(0, 10), class = \"b\", coef = \"WeekendTRUE\")\n)\n\n# Run the model!\nmodel_bayes &lt;- brm(bf(inspection_score ~ Weekend + NumberofLocations + Year),\n                   data = inspections,\n                   prior = priors,\n                   chains = 4, iter = 2000, cores = 4, seed = 1234)\n## Compiling Stan program...\n## Start sampling\n\n\nPhew. That took a while to run, but it ran! Now we can check the results:\n\n\nCode\ntidy(model_bayes, conf.int = TRUE)\n## # A tibble: 5 × 8\n##   effect   component group    term              estimate std.error conf.low conf.high\n##   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1 fixed    cond      &lt;NA&gt;     (Intercept)       225.     12.5      201.      250.    \n## 2 fixed    cond      &lt;NA&gt;     WeekendTRUE         1.45    0.424      0.603     2.28  \n## 3 fixed    cond      &lt;NA&gt;     NumberofLocations  -0.0191  0.000440  -0.0200   -0.0183\n## 4 fixed    cond      &lt;NA&gt;     Year               -0.0647  0.00620   -0.0770   -0.0530\n## 5 ran_pars cond      Residual sd__Observation     6.04    0.0253     5.99      6.09\n\n\nOur estimate for the weekend boost, or \\(\\hat{\\theta}\\), is 1.45, which is basically the same as the frequentist estimate we found before. We have an interval too, but it’s not a confidence interval—it’s a credible interval. Instead of telling us about the range of the confidence interval net, this credible interval tells us the probability that \\(\\hat{\\theta}\\) falls in that range. It’s essentially the probability of the actual value, not the probability of the range. Based on this, there’s a 95% chance that—given the data we have—the weekend score boost (\\(\\hat{\\theta}\\)) is between 0.6 and 2.28.\nWe can visualize this posterior distribution to see more information than we could with our frequentist estimate. Remember, our simulation estimated thousands of possible coefficients for WeekendTRUE, and each of them are equally likely. The value that we see in tidy() is the median of all these simulated coefficients, or draws. We can see a few of them here:\n\n\nCode\nmodel_bayes %&gt;%\n  spread_draws(b_WeekendTRUE) %&gt;%\n  head(10)\n## # A tibble: 10 × 4\n##    .chain .iteration .draw b_WeekendTRUE\n##     &lt;int&gt;      &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;\n##  1      1          1     1          1.01\n##  2      1          2     2          1.85\n##  3      1          3     3          1.85\n##  4      1          4     4          1.96\n##  5      1          5     5          1.70\n##  6      1          6     6          1.75\n##  7      1          7     7          1.71\n##  8      1          8     8          2.36\n##  9      1          9     9          1.53\n## 10      1         10    10          1.34\n\n\nSometimes the weekend boost is 1.2, sometimes 1.7, sometimes 1.3, etc. There’s a lot of variation in there. We can plot all these simulated coefficients to see where they mostly cluster:\n\n\nCode\nweekend_draws &lt;- model_bayes %&gt;%\n  spread_draws(b_WeekendTRUE)\n\nggplot(weekend_draws, aes(x = b_WeekendTRUE)) +\n  stat_halfeye() +\n  labs(caption = \"Point shows median value;\\nthick black bar shows 66% credible interval;\\nthin black bar shows 95% credible interval\")\n\n\n\n\n\n\n\n\n\nThe weekend point boost \\(\\hat{\\theta}\\) is mostly clustered around 1–2, and 95% of those draws are between 0.6 and 2.28. We’re thus 95% sure that the actual weekend point boost is between 0.6 and 2.28 with a median of 1.45.\nWe can also look at this distribution a slightly different way by collapsing all those posterior draws into 100 possible values. Each of these dots is equally likely, and the true value of \\(\\theta\\) could be any of them, but again, most are clustered around 1.45:\n\n\nCode\nggplot(weekend_draws, aes(x = b_WeekendTRUE)) +\n  stat_dotsinterval(quantiles = 100) +\n  labs(caption = \"Point shows median value;\\nthick black bar shows 66% credible interval;\\nthin black bar shows 95% credible interval\")"
  },
  {
    "objectID": "resource/bayes.html#general-summary-of-intervals",
    "href": "resource/bayes.html#general-summary-of-intervals",
    "title": "Bayesian statistics resources",
    "section": "General summary of intervals",
    "text": "General summary of intervals\nSo, we’ve seen two different philosophies for quantifying uncertainty with confidence intervals and credible intervals. Here’s a general overview of the two approaches and how you can interpret them:\n\n\n\n\n\n\n\n\n\n\n\nFrequentism\nBayesianism\n\n\n\n\nApproach\n\\(P(\\text{Data} \\mid \\theta)\\)\n\\(P(\\theta \\mid \\text{Data})\\)\n\n\n\n\\(\\theta\\) is a fixed single value; data is variable and can be repeatedly sampled\n\\(\\theta\\) is variable and has uncertainty; data is fixed (you only have one sample)\n\n\nHow to do it in R\nlm(...)\nlibrary(brms)\nbrm(...)\n\n\nName\nConfidence interval\nCredible interval (or posterior interval)\n\n\nIntuition\nProbability of the range\nProbability of the actual value\n\n\nInterpretation template\nThere's a 95% probability that this range contains the true value of \\(\\theta\\)\nThere's a 95% probability that the true value of \\(\\theta\\) falls in this range.\n\n\n\nFew people naturally think like this\nPeople do naturally think like this"
  },
  {
    "objectID": "resource/bayes.html#two-ways-of-making-decisions-with-posterior-distributions",
    "href": "resource/bayes.html#two-ways-of-making-decisions-with-posterior-distributions",
    "title": "Bayesian statistics resources",
    "section": "Two ways of making decisions with posterior distributions",
    "text": "Two ways of making decisions with posterior distributions\nIn the world of frequentism, we’re interested in whether coefficients are statistically different from 0 in a null world where there’s no effect. We rely on p-values to see the probability of seeing an estimate at least as large as what we’ve calculated in a hypothetical world where that estimate is actually 0. This is a really non-intuitive way of thinking about the world (imaginary null worlds?!), so everyone always misinterprets p-values.\nRemember what you read in Imbens’s article though—in real life, very few people care about whether a coefficient is significantly different from a hypothetical null. Instead, people want to know how certain you are of the estimate and what it means practically. Is it for sure a positive effect, or could it maybe be zero or maybe be negative? Significance stars can’t tell us much about those questions, but posterior Bayesian intervals can.\n\nProbability of direction\nOne question we can answer with Bayesian results is “How certain are we that this estimate is positive (or negative)?” Are we sure the weekend scores are higher on average, or could they sometimes be negative? Are we sure that the average treatment effect of your program decreases poverty, or could it maybe have a positive effect instead?\nTo figure this out, we can calculate something called the “probability of direction,” or the proportion of posterior draws that are above (or below) some arbitrary number. For instance, what’s the probability that the weekend boost is positive (or greater than 0)?\n\n\nCode\n# Find the proportion of posterior draws that are bigger than 0\nweekend_draws %&gt;% \n  summarize(prop_greater_0 = sum(b_WeekendTRUE &gt; 0) / n())\n## # A tibble: 1 × 1\n##   prop_greater_0\n##            &lt;dbl&gt;\n## 1          0.999\n\n\nWhoa. 99.9% of the posterior draws for the weekend boost are greater than 0, meaning that there’s a 99.9% chance that the coefficient is positive, given the data we have.\nThe neat thing about the probability of direction is that we can choose whatever value we want as the threshold. Let’s say the state health director wants to know if weekend scores are higher than weekday scores, but she’s fine with just a little boost (weekends are nice! inspectors are happier!). Pretend that she thinks an average difference of 1 or lower isn’t a big concern, but seeing a difference greater than 1 is a signal that weekend inspectors are maybe being too lenient. We can use 1 as our threshold instead:\n\n\nCode\n# Find the proportion of posterior draws that are bigger than 1\nweekend_draws %&gt;% \n  summarize(prop_greater_0 = sum(b_WeekendTRUE &gt; 1) / n())\n## # A tibble: 1 × 1\n##   prop_greater_0\n##            &lt;dbl&gt;\n## 1          0.860\n\n\nBased on this, 84% of the draws are higher than 1, so there’s an 84% chance that the actual \\(\\theta\\) is greater than 1. Notice how there’s no discussion of significance here—no alpha thresholds, no stars, no null worlds. We just have a probability that \\(\\hat{\\theta}\\) is above 1. We can even visualize it. Everything to the right of that vertical line at 1 is “significant” (but not significant with null worlds and stars).\n\n\nCode\nggplot(weekend_draws, aes(x = b_WeekendTRUE)) +\n  stat_halfeye(aes(fill_ramp = stat(x &gt; 1)), fill = \"red\") +\n  scale_fill_ramp_discrete(from = \"darkred\", guide = \"none\") +\n  geom_vline(xintercept = 1) +\n  labs(caption = \"Point shows median value;\\nthick black bar shows 66% credible interval;\\nthin black bar shows 95% credible interval\")\n## Warning: `stat(x &gt; 1)` was deprecated in ggplot2 3.4.0.\n## ℹ Please use `after_stat(x &gt; 1)` instead.\n\n\n\n\n\n\n\n\n\nShould the state health director be concerned? Probably. There’s an 84% chance that weekend inspection scores are at least 1 point higher than weekday scores, on average, given the data we have.\n\n\nRegion of practical equivalence (ROPE)\nLooking at the probability of direction is helpful if you are concerned whether an effect is positive or negative (i.e. greater or less than 0), but it’s also a little weird to think about because we’re testing if something is greater or less than some specific single number. In our example of the health director, we pretended that she cared whether the average weekend score was 1 point higher, but that’s arbitrary.\nAnother approach is that we can think of a range of \\(\\theta\\) where there’s practically no effect. Think of this as a “dead zone” of sorts. If \\(\\hat{\\theta}\\) is 0, we know there’s no effect. If \\(\\hat{\\theta}\\) is something tiny like 0.2 or -0.3, we probably don’t actually care—that’s a tiny amount and could just be because of measurement error. It’s not anything really actionable. If \\(\\hat{\\theta}\\) is big like 1.3 or -2.4 or whatever, then we have cause to worry, but if the estimate is in the “dead zone” (however we want to define it), then we shouldn’t really care or worry.\nThe official Bayesian term for this “dead zone” is the region of practical equivalence (ROPE). There are lots of ways to determine this dead zone—you can base it on experience with the phenomenon (e.g., if you’re the health director and know a lot about inspection scores, you know what kind of score ranges matter), or you can base it on the data you have (e.g., -0.1 * sd(outcome) to 0.1 * sd(outcome)).\nFor this example, let’s pretend that the health director tells you that any effect between −0.5 and 0.5 doesn’t matter—for her, those kind of values would be the same as 0. Now that we have a dead zone or ROPE, we can calculate the proportion of coefficient draws that fall outside of that ROPE:\n\n\nCode\n# Find the proportion of posterior draws that are bigger than 0.5 or less than -0.5\nweekend_draws %&gt;% \n  summarize(prop_outside_rope = 1 - sum(b_WeekendTRUE &gt;= -0.5 & b_WeekendTRUE &lt;= 0.5) / n())\n## # A tibble: 1 × 1\n##   prop_outside_rope\n##               &lt;dbl&gt;\n## 1             0.988\n\n\n\n\nCode\nggplot(weekend_draws, aes(x = b_WeekendTRUE)) +\n  stat_halfeye(aes(fill_ramp = stat(x &gt;= 0.5 | x &lt;= -0.5)), fill = \"red\") +\n  scale_fill_ramp_discrete(from = \"darkred\", guide = \"none\") +\n  annotate(geom = \"rect\", xmin = -0.5, xmax = 0.5, ymin = -Inf, ymax = Inf, fill = \"purple\", alpha = 0.3) +\n  annotate(geom = \"label\", x = 0, y = 0.75, label = \"ROPE\\n(dead zone)\") +\n  labs(caption = \"Point shows median value;\\nthick black bar shows 66% credible interval;\\nthin black bar shows 95% credible interval\")\n\n\n\n\n\n\n\n\n\nGiven this data, 98% of the posterior distribution of the weekend boost is outside of the ROPE, or dead zone, so we can consider this to be “significant” (again, this is a tricky word because it has nothing to do with null worlds and stars!).\nThere are some debates over what you should check with the ROPE. Some people say that you should look at how much of the 95% credible interval is inside the dead zone; other say you should look at how much of the entire distribution is inside the dead zone. We just did the latter, with the whole distribution. If we want to see how much of the area within the credible interval is inside the dead zone, we can change the code a little to filter those observations out:\n\n\nCode\n# Extract the 95% confidence interval range\nweekend_cred_int &lt;- weekend_draws %&gt;% \n  median_hdi()\nweekend_cred_int$.lower\n## [1] 0.64\n\n# Find the proportion of posterior draws that are bigger than 0.5 or less than \n# -0.5, but only look inside the 95% credible interval\nweekend_draws %&gt;% \n  # Only look inside the credible interval\n  filter(b_WeekendTRUE &gt;= weekend_cred_int$.lower & b_WeekendTRUE &lt;= weekend_cred_int$.upper) %&gt;% \n  summarize(prop_outside_rope = 1 - sum(b_WeekendTRUE &gt;= -0.5 & b_WeekendTRUE &lt;= 0.5) / n())\n## # A tibble: 1 × 1\n##   prop_outside_rope\n##               &lt;dbl&gt;\n## 1                 1\n\n\nIf we look only at the 95% credible interval of the posterior, there’s a 0% chance that any of those estimated coefficients are in the dead zone / ROPE. There’s a 100% chance that the credible interval doesn’t touch the ROPE. You can see this visually too—look at the figure above with the purple ROPE. The thin black bar that shows the 95% credible interval doesn’t show up in the purple area.\nWhich approach is better—using full distribution or just using the credible interval? Who knows. That’s up to you.\nFinally, here we decided on the ROPE kind of arbitrarily as −0.5 to 0.5, but there are more systematic ways of doing it. One common and standard suggestion is to use −0.1 and 0.1 times the standard deviation of the outcome variable:\n\n\nCode\nc(-0.1, 0.1) * sd(inspections$inspection_score)\n## [1] -0.63  0.63\n\n\nBased on this approach, our ROPE/dead zone should be −0.63 to 0.63. Let’s see how that looks:\n\n\nCode\n# Find the proportion of posterior draws that are bigger than 0.5 or less than \n# -0.5, but only look inside the 95% credible interval\nweekend_draws %&gt;% \n  # Only look inside the credible interval\n  filter(b_WeekendTRUE &gt;= weekend_cred_int$.lower & b_WeekendTRUE &lt;= weekend_cred_int$.upper) %&gt;% \n  summarize(prop_outside_rope = 1 - sum(b_WeekendTRUE &gt;= -0.63 & b_WeekendTRUE &lt;= 0.63) / n())\n## # A tibble: 1 × 1\n##   prop_outside_rope\n##               &lt;dbl&gt;\n## 1                 1\n\n\n\n\nCode\nggplot(weekend_draws, aes(x = b_WeekendTRUE)) +\n  stat_halfeye(aes(fill_ramp = stat(x &gt;= 0.63 | x &lt;= -0.63)), fill = \"red\") +\n  scale_fill_ramp_discrete(from = \"darkred\", guide = \"none\") +\n  annotate(geom = \"rect\", xmin = -0.63, xmax = 0.63, ymin = -Inf, ymax = Inf, fill = \"purple\", alpha = 0.3) +\n  annotate(geom = \"label\", x = 0, y = 0.75, label = \"ROPE\\n(dead zone)\") +\n  labs(caption = \"Point shows median value;\\nthick black bar shows 66% credible interval;\\nthin black bar shows 95% credible interval\")\n\n\n\n\n\n\n\n\n\nThis changes our results just a tiny bit. 97% of the full posterior distribution and 99.7% of the credible interval falls outside this ROPE. Neat. We can thus safely say that the weekend effect, or our estimate of \\(\\theta\\) is definitely practical and substantial (or “significant” if we want to play with that language)."
  },
  {
    "objectID": "news/2022-08-22_getting-help.html",
    "href": "news/2022-08-22_getting-help.html",
    "title": "How to reach out for help",
    "section": "",
    "text": "← News\n\n\n\nHi everyone!\nYou absolutely can (and should) reach out when you get stuck. I’m super responsive on Slack and e-mail. If you ask a question on the #help channel in Slack, others can help too. No question is too tricky or embarrassing, I promise. Computers are extraordinarily literal and tiny typos will often mess you up for a long time—I’ve lost countless time because of missing commas and misspelled words (curse you lenght()). Please feel comfortable reaching out.\n\nAsk early and often\nI’m a big believer in the 30 minute rule. If you’re stuck and not making progress on a task for 30 minutes, reach out for help from the community.\n\n\nBe nice\nOne of the great parts about the online R community is that the team at RStudio has actually hired people to help promote community norms. Like that’s their whole job—community evangelist (see @dataandme and @RachaelDempsey for instance). The R world is probably one of the nicest corners of the programming internet because of these norms—there’s an emphasis on helping beginners, being kind and respectful, and cheerfully helping as much as possible. Watch the #rstats hashtag on Twitter, look at the “r” tag on StackOverflow, and look at discussions at the RStudio Community and you’ll see kindness in action.\nThis was not always the case. 10ish years ago, before the RStudio people made a concerted effort to create community, the online R world was pretty mean and toxic, with forums run by a few really grumpy statisticians who’d belittle you if you asked a poorly worded question. It was awful. That kind of attitude often still persists in other languages (hooo boy try asking a beginner question about Python at StackOverflow 😬), but the R world has tried really hard to be welcoming.\nI embrace that attitude when teaching R, and I encourage you all to do the same. Reach out for help early and often. Do not suffer in silence. Do not spend hours and hours stuck on an issue before reaching out for help. If you feel comfortable, reach out publicly on the #help channel rather than a Slack DM so that others can help. This helps build and strengthen the community within our class and within the R community more broadly.\n\n\nAsk in a way that helps the answerer\nThere are a few easy guidelines to remember when asking for help:\n\nBe kind.\nTry asking questions with as complete information as possible. Rather than saying something like “my code isn’t working” and that’s it, provide more background (it’s hard to read your computer’s mind). Say specifically what you’re trying to do and provide code when possible. You can actually format R code on Slack if you click on the little lightning icon in the bottom left of the typing area and search for “text snippet”—that’ll open a dialog that will let you paste in text and add R syntax highlighting. You can also paste your code between triple backticks on Slack and it’ll format it in monospaced font (though not with the neat syntax highlighting that you get when using Slack’s text snippet thing):\n```\nggplot(blah) + geom_point()\n```\nYou can also take screenshots (use ⌘+shift+4 on macOS to save a screenshot to your Desktop, or ⌘+⌥+shift+4 to save a screenshot directly to the clipboard; use Windows+shift+S on Windows to save a screenshot directly to the clipboard). I’ve had people send photos from their phones too. The one issue with screenshots/photos is that it’s harder for people to get the code out of Slack and into RStudio on their computer to troubleshoot, since you can’t copy/paste from an image.\nTry making your question a reproducible example (or reprex). Reprexes are the best way to (1) get help online and (2) fix issues on your own.\nMaking a good reprex is tricky, but it’s a very valuable skill to know (regardless of programming language!). Here are some helpful resources for making them:\n\n What’s a reproducible example (reprex) and how do I do one?\n So you’ve been asked to make a reprex\n The reprex package\n\n\n\n\nDon’t suffer in silence\nAnd that’s it. Ask questions in ways that will help answerers answer them and be nice about it. When answering questions, be nice about it. Ask lots of questions. Answer lots of questions.\nOnce again, do not suffer in silence. I’ve had past students tell me that’s like the one thing they’ll remember from my classes—do not suffer in silence. I mean it, and I’ll keep saying it throughout the semester (because often in your past courses and degrees, you’ve been discouraged from reaching out or from building communities or whatever—that is not the case here)."
  },
  {
    "objectID": "news/2022-08-15_announcements-updates.html",
    "href": "news/2022-08-15_announcements-updates.html",
    "title": "Announcements and updates",
    "section": "",
    "text": "← News\n\n\n\nOne last thing!\nOver the course of the semester, I’ll be sending you lots of updates and announcements and FAQs based on your weekly check-ins.\nMy philosophy for this class is to let you maintain access to as much content as possible, which is why so little of the the class material is on iCollege.\nI will post all these announcements and e-mails at the “News section of the course website. This means that even after you finish the class and lose access to iCollege, and even after you graduate from GSU and lose access to your (gsu.edu?) e-mail address, you’ll still have a searchable archive of messages and FAQs from this class.\nI’ll let you know when there’s a new item in the news section in a few different ways:\n\nI’ll e-mail you a link to the newest message. I’ll use the e-mail address you have listed in PAWS—if you want me to use a different address, let me know and I’ll update my list,\nNew messages should post automatically to the #general channel in Slack\nIf you use an RSS feed reader (RIP Google Reader), you can subscribe to an RSS feed of the news section. There’s a link at the bottom of the news page.\n\nPhew. That should be it from me for a while. Remember to read the syllabus and the rest of the course website, answer the welcome survey, sign up for Slack, and join the RStudio.cloud workspace. Also, remember to take care of yourselves! I mean every word in the “Learning during a pandemic” section of the syllabus. This all sucks so much, and I will try my hardest to accommodate your needs throughout the semester.\nThanks!"
  },
  {
    "objectID": "news/2022-08-08_important-r-stuff.html",
    "href": "news/2022-08-08_important-r-stuff.html",
    "title": "Important R stuff",
    "section": "",
    "text": "← News\n\n\n\nFrom reading the syllabus you’ll notice that we’re using R in this class (though you can certainly use Stata too if you really want). R is free (!!), and highly sought after by employers, but it has a little bit of an initial learning curve. You’ll get the hang of it, though, I promise! I’m a certified RStudio instructor (see https://education.rstudio.com/trainers/), so I’ve been specially trained to teach statistical programming. Again, I promise that you’ll learn a ton.\nYou’ll be doing your stats work in RStudio this semester. While R and RStudio are free and open source, they can sometimes be tricky to install. To make life simpler, you can run RStudio in your browser without having to install anything (!!!). Over the course of the semester you’ll want to eventually install everything on your actual computer, since it’ll run faster there, but you won’t need to install anything to get started. I’ll e-mail you a link to join the class workspace.\nIn the meantime, you can also install everything on your actual computer if you follow these instructions (eventually you should do this—it’s best to run R on your own computer, but it’s totally fine to run everything at RStudio Cloud for the first few weeks)\nIf you have some free time over the next week and you feel like getting a head start, I would highly recommend going through a few of RStudio’s R Primers at https://rstudio.cloud/learn/primers. Don’t worry if you don’t have time to go through these introductory primers/tutorials! Your first problem set is essentially doing those primers (see here for the ones you’ll need to do), so you don’t have to get a head start now if you don’t want to.\nOnce again, I promise that you can do this and have a blast in this class!"
  },
  {
    "objectID": "jacobAssignments/05-problem-set-new.html",
    "href": "jacobAssignments/05-problem-set-new.html",
    "title": "Problem set 5",
    "section": "",
    "text": "For this problem set, you’ll reproduce the results from one of the papers that you looked at in your threats to validity assignment:\nThe full published paper is posted on iCollege under “Content &gt; Validity assignment” (since you used the paper for that assignment). It’s not posted publicly here because of copyright reasons. The data comes from Di Tella and Schargrodsky’s data appendix available at their study’s AER webpage, and I’ve included it in the .zip file for the assignment.\nThis paper uses difference-in-differences to estimate the causal effect of increased policing on car thefts. Now that you know all about diff-in-diff, you can create their same results!\nThe answer key from Problem Set 4 (where you also did diff-in-diff) + this example page will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "jacobAssignments/05-problem-set-new.html#instructions",
    "href": "jacobAssignments/05-problem-set-new.html#instructions",
    "title": "Problem set 5",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-5.Rproj:  problem-set-5.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, haven, broom, fixest, and modelsummary. If you try to load one of those packages with library(tidyverse) or library(haven), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 5” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 5.”)\nRename the R Markdown file named your-name_problem-set-5.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold. Your job is to answer those questions. You don’t need to put your answers in bold or ALL CAPS or anything, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on diff-in-diff—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "jacobAssignments/03-problem-set-new.html",
    "href": "jacobAssignments/03-problem-set-new.html",
    "title": "Problem set 3",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but again, it’s mostly copying/pasting chunks of code and changing things.\nFor this problem set, you’ll practice analyzing RCTs and working with matching and inverse probability weighting. These two examples will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown this time (and from now on). You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "jacobAssignments/03-problem-set-new.html#instructions",
    "href": "jacobAssignments/03-problem-set-new.html#instructions",
    "title": "Problem set 3",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-3.Rproj:  problem-set-3.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, MatchIt, modelsummary, and patchwork. If you try to load one of those packages with library(tidyverse) or library(MatchIt), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 3” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 3.”)\nRename the R Markdown file named your-name_problem-set-3.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold (e.g. **What is the ATE?**). Your job is to answer those questions. You don’t need to put your answers in bold, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on RCTs and the example page on matching and IPW—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "jacobAssignments/01-problem-set-new.html",
    "href": "jacobAssignments/01-problem-set-new.html",
    "title": "Problem set 1",
    "section": "",
    "text": "Go the the example page for this week, “Welcome to R, RStudio, and the tidyverse”, and work through the different primers and videos in the four parts of the page.\nIt seems like there’s a lot on the page, but they’re short and go fairly quickly (especially as you get the hang of the syntax). Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck and want to skip some (or if it gets too easy), go right ahead and skip them!"
  },
  {
    "objectID": "jacobAssignments/01-problem-set-new.html#task-1-introduce-yourself-to-r-rstudio-and-the-tidyverse",
    "href": "jacobAssignments/01-problem-set-new.html#task-1-introduce-yourself-to-r-rstudio-and-the-tidyverse",
    "title": "Problem set 1",
    "section": "",
    "text": "Go the the example page for this week, “Welcome to R, RStudio, and the tidyverse”, and work through the different primers and videos in the four parts of the page.\nIt seems like there’s a lot on the page, but they’re short and go fairly quickly (especially as you get the hang of the syntax). Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck and want to skip some (or if it gets too easy), go right ahead and skip them!"
  },
  {
    "objectID": "jacobAssignments/01-problem-set-new.html#task-2-make-an-rstudio-project",
    "href": "jacobAssignments/01-problem-set-new.html#task-2-make-an-rstudio-project",
    "title": "Problem set 1",
    "section": "Task 2: Make an RStudio Project",
    "text": "Task 2: Make an RStudio Project\n\nUse either RStudio.cloud or RStudio on your computer (preferably RStudio on your computer! Follow these instructions to get started!) to create a new RStudio Project. Refer to the example page you read in Task 1 for instructions\nCreate a folder named “data” in the project folder you just made.\nDownload this CSV file and place it in that folder:\n\n cars.csv\n\nIn RStudio, go to “File” &gt; “New File…” &gt; “R Markdown…” and click “OK” in the dialog without changing anything.\nDelete all the placeholder text in that new file and replace it with this:\n---\ntitle: \"Problem set 1\"\nauthor: \"Put your name here\"\noutput: html_document\n---\n\n\n```{r load-libraries-data, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\n\ncars &lt;- read_csv(\"data/cars.csv\")\n```\n\n\n\n# Learning R\n\nTell me that you worked through the primers and videos and examples at the example page for this week:\n\nWRITE SOMETHING HERE LIKE \"I did all the primers and had the time of my life!\" or whatever.\n\n\n# My first plots\n\nInsert a chunk below and use it to create a scatterplot (hint: `geom_point()`) with diplacement (`displ`) on the x-axis, city MPG (`cty`) on the y-axis, and with the points colored by drive (`drv`).\n\nPUT CHUNK HERE\n\nInsert a chunk below and use it to create a histogram (hint: `geom_histogram()`) with highway MPG (`hwy`) on the x-axis. Do not include anything on the y-axis (`geom_histogram()` will do that automatically for you). Choose an appropriate bin width. If you're brave, facet by drive (`drv`).\n\nPUT CHUNK HERE\n\n\n# My first data manipulation\n\nInsert a chunk below and use it to calculate the average city MPG (`cty`) by class of car (`class`). This won't be a plot---it'll be a table. Hint: use a combination of `group_by()` and `summarize()`.\n\nPUT CHUNK HERE\nSave the R Markdown file with some sort of name (without any spaces!)\nYour project folder should look something like this:"
  },
  {
    "objectID": "jacobAssignments/01-problem-set-new.html#task-3-work-with-r",
    "href": "jacobAssignments/01-problem-set-new.html#task-3-work-with-r",
    "title": "Problem set 1",
    "section": "Task 3: Work with R",
    "text": "Task 3: Work with R\n\nRemove the text that says “PUT CHUNK HERE” and insert a new R code chunk. Either type ctrl + alt + i on Windows, or ⌘ + ⌥ + i on macOS, or use the “Insert Chunk” menu:\n\n\n\n\n\n\n\n\n\n\n\nFollow the instructions for the three chunks of code.\nKnit your document as a Word file (or PDF if you’re brave and installed LaTeX). Use the “Knit” menu:\n\n\n\n\n\n\n\n\n\n\n\nUpload the knitted document to iCollege.\n🎉 Party! 🎉\n\n\n\n\n\n\n\nTip\n\n\n\nYou’ll be doing this same process for all your future problem sets. Each problem set will involve an R Markdown file. You can either create a new RStudio Project directory for all your work:\n\n\n\n\n\n\n\n\n\nOr you can create individual projects for each assignment and project:"
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "content/14-content.html",
    "href": "content/14-content.html",
    "title": "Ethics, stories, and curiosity",
    "section": "",
    "text": "This looks like a lot, but most of these are quite short!\n\n\n\n Miguel A. Hernán, “The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data” (Hernán 2018)\n Hannah Fresques and Meg Marco, “‘Your Default Position Should Be Skepticism’ and Other Advice for Data Journalists From Hadley Wickham,” ProPublica, June 10, 2019\n\n\n\n\n\n Chapter 14 in Impact Evaluation in Practice (Gertler et al. 2016)\n Martin Krzywinski and Alberto Cairo, “Storytelling”\n Ben Wellington, “Making data mean more through storytelling”\n Will Schoder, “Every Story is the Same”\n\n\n\n\nKeep in mind throughout all these readings that an “algorithm” in these contexts is typically some fancy type of regression model where the outcome variable is something binary like “Safe babysitter/unsafe babysitter,” “Gave up seat in past/didn’t give up seat in past”, or “Violated probation in past/didn’t violate probation in past”, and the explanatory variables are hundreds of pieces of data that might predict those outcomes (social media history, flight history, race, etc.).\nData scientists build a (sometimes proprietary and complex) model based on existing data, plug in values for any given new person, multiply that person’s values by the coefficients in the model, and get a final score in the end for how likely someone is to be a safe babysitter or how likely someone is to return to jail.\n\n DJ Patil, “A Code of Ethics for Data Science” (if your’re interested in this, also check out Mike Loukides, Hilary Mason, and DJ Patil, Ethics and Data Science\n “AI in 2018: A Year in Review”\n “How Big Data Is ‘Automating Inequality’”\n “In ‘Algorithms of Oppression,’ Safiya Noble finds old stereotypes persist in new media”\n 99% Invisible, “The Age of the Algorithm”: Note that this is a podcast, or a 20ish minute audio story. Listen to this.\n On the Media, “Biased Algorithms, Biased World”\n “Wanted: The ‘perfect babysitter.’ Must pass AI scan for respect and attitude.”\n “Companies are on the hook if their hiring algorithms are biased”\n “Courts use algorithms to help determine sentencing, but random people get the same results”\n David Heinemeier Hansson’s rant on the Apple Card\n\nAnd Jamie Heinemeier Hansson’s response"
  },
  {
    "objectID": "content/14-content.html#readings",
    "href": "content/14-content.html#readings",
    "title": "Ethics, stories, and curiosity",
    "section": "",
    "text": "This looks like a lot, but most of these are quite short!\n\n\n\n Miguel A. Hernán, “The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data” (Hernán 2018)\n Hannah Fresques and Meg Marco, “‘Your Default Position Should Be Skepticism’ and Other Advice for Data Journalists From Hadley Wickham,” ProPublica, June 10, 2019\n\n\n\n\n\n Chapter 14 in Impact Evaluation in Practice (Gertler et al. 2016)\n Martin Krzywinski and Alberto Cairo, “Storytelling”\n Ben Wellington, “Making data mean more through storytelling”\n Will Schoder, “Every Story is the Same”\n\n\n\n\nKeep in mind throughout all these readings that an “algorithm” in these contexts is typically some fancy type of regression model where the outcome variable is something binary like “Safe babysitter/unsafe babysitter,” “Gave up seat in past/didn’t give up seat in past”, or “Violated probation in past/didn’t violate probation in past”, and the explanatory variables are hundreds of pieces of data that might predict those outcomes (social media history, flight history, race, etc.).\nData scientists build a (sometimes proprietary and complex) model based on existing data, plug in values for any given new person, multiply that person’s values by the coefficients in the model, and get a final score in the end for how likely someone is to be a safe babysitter or how likely someone is to return to jail.\n\n DJ Patil, “A Code of Ethics for Data Science” (if your’re interested in this, also check out Mike Loukides, Hilary Mason, and DJ Patil, Ethics and Data Science\n “AI in 2018: A Year in Review”\n “How Big Data Is ‘Automating Inequality’”\n “In ‘Algorithms of Oppression,’ Safiya Noble finds old stereotypes persist in new media”\n 99% Invisible, “The Age of the Algorithm”: Note that this is a podcast, or a 20ish minute audio story. Listen to this.\n On the Media, “Biased Algorithms, Biased World”\n “Wanted: The ‘perfect babysitter.’ Must pass AI scan for respect and attitude.”\n “Companies are on the hook if their hiring algorithms are biased”\n “Courts use algorithms to help determine sentencing, but random people get the same results”\n David Heinemeier Hansson’s rant on the Apple Card\n\nAnd Jamie Heinemeier Hansson’s response"
  },
  {
    "objectID": "content/14-content.html#slides",
    "href": "content/14-content.html#slides",
    "title": "Ethics, stories, and curiosity",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nWhat did we just learn?\n\n\nEthics of data analyitcs (a)\n\n\nEthics of data analytics (b)\n\n\nEthics of data analytics (c)\n\n\nEthics of storytelling (a)\n\n\nEthics of storytelling (b)\n\n\nEthics of storytelling (c)\n\n\nEthics of storytelling (d)\n\n\nCuriosity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/14-content.html#videos",
    "href": "content/14-content.html#videos",
    "title": "Ethics, stories, and curiosity",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nWhat did we just learn?\nEthics of data analyitcs (a)\nEthics of data analytics (b)\nEthics of data analytics (c)\nEthics of storytelling (a)\nEthics of storytelling (b)\nEthics of storytelling (c)\nEthics of storytelling (d)\nCuriosity\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Instrumental variables II + Regression discontinuity II",
    "section": "",
    "text": "The example page on complier average causal effects shows how to use R to disentangle complier average causal effects\nThe example page on fuzzy regression discontinuity shows how to use R to use instrumental variables in fuzzy regression discontinuity, both parametrically and nonparametrically"
  },
  {
    "objectID": "content/12-content.html#readings",
    "href": "content/12-content.html#readings",
    "title": "Instrumental variables II + Regression discontinuity II",
    "section": "",
    "text": "The example page on complier average causal effects shows how to use R to disentangle complier average causal effects\nThe example page on fuzzy regression discontinuity shows how to use R to use instrumental variables in fuzzy regression discontinuity, both parametrically and nonparametrically"
  },
  {
    "objectID": "content/12-content.html#slides",
    "href": "content/12-content.html#slides",
    "title": "Instrumental variables II + Regression discontinuity II",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nTreatment effects and compliance\n\n\nRandomized promotion\n\n\nFuzzy regression discontinuity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/12-content.html#videos",
    "href": "content/12-content.html#videos",
    "title": "Instrumental variables II + Regression discontinuity II",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nTreatment effects and compliance\nRandomized promotion\nFuzzy regression discontinuity\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/12-content.html#in-class-stuff",
    "href": "content/12-content.html#in-class-stuff",
    "title": "Instrumental variables II + Regression discontinuity II",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nWeek 12 FAQ slides (PDF)\n Live R script"
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Regression discontinuity I",
    "section": "",
    "text": "Chapter 6 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 20 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on regression discontinuity shows how to use R to analyze and estimate causal effects with regression discontinuity"
  },
  {
    "objectID": "content/10-content.html#readings",
    "href": "content/10-content.html#readings",
    "title": "Regression discontinuity I",
    "section": "",
    "text": "Chapter 6 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 20 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on regression discontinuity shows how to use R to analyze and estimate causal effects with regression discontinuity"
  },
  {
    "objectID": "content/10-content.html#slides",
    "href": "content/10-content.html#slides",
    "title": "Regression discontinuity I",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nArbitrary cutoffs and causal inference\n\n\nDrawing lines and measuring gaps\n\n\nMain RDD concerns\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/10-content.html#videos",
    "href": "content/10-content.html#videos",
    "title": "Regression discontinuity I",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nArbitrary cutoffs and causal inference\nDrawing lines and measuring gaps\nMain RDD concerns\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/10-content.html#in-class-stuff",
    "href": "content/10-content.html#in-class-stuff",
    "title": "Regression discontinuity I",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nWeek 10 FAQ slides (PDF)\nWeek 10 R code (on RStudio.cloud)"
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Difference-in-differences I",
    "section": "",
    "text": "Chapter 7 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 18 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/08-content.html#readings",
    "href": "content/08-content.html#readings",
    "title": "Difference-in-differences I",
    "section": "",
    "text": "Chapter 7 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 18 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/08-content.html#slides",
    "href": "content/08-content.html#slides",
    "title": "Difference-in-differences I",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nQuasi-experiments\n\n\nInteractions & regression\n\n\nTwo wrongs make a right\n\n\nDiff-in-diff assumptions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/08-content.html#videos",
    "href": "content/08-content.html#videos",
    "title": "Difference-in-differences I",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nQuasi-experiments\nInteractions & regression\nTwo wrongs make a right\nDiff-in-diff assumptions\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/08-content.html#in-class-stuff",
    "href": "content/08-content.html#in-class-stuff",
    "title": "Difference-in-differences I",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 8 FAQ slides (PDF)\nSession 8 R code (on RStudio.cloud)"
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Threats to validity",
    "section": "",
    "text": "Guido Imbens, “Statistical Significance, p-Values, and the Reporting of Uncertainty” (Imbens 2021). This is available on iCollege, and it’s also free here.\n Randall Munroe, “Significant”\n Alexander Coppock, “10 Things to Know About Statistical Power”\n Play around with FiveThirtyEight, “Hack Your Way To Scientific Glory”\n Chapter 9 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 11 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/06-content.html#readings",
    "href": "content/06-content.html#readings",
    "title": "Threats to validity",
    "section": "",
    "text": "Guido Imbens, “Statistical Significance, p-Values, and the Reporting of Uncertainty” (Imbens 2021). This is available on iCollege, and it’s also free here.\n Randall Munroe, “Significant”\n Alexander Coppock, “10 Things to Know About Statistical Power”\n Play around with FiveThirtyEight, “Hack Your Way To Scientific Glory”\n Chapter 9 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 11 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/06-content.html#slides",
    "href": "content/06-content.html#slides",
    "title": "Threats to validity",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nConstruct validity\n\n\nStatistical conclusion validity\n\n\nInternal validity\n\n\nExternal validity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/06-content.html#videos",
    "href": "content/06-content.html#videos",
    "title": "Threats to validity",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nConstruct validity\nStatistical conclusion validity\nInternal validity\nExternal validity\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/06-content.html#in-class-stuff",
    "href": "content/06-content.html#in-class-stuff",
    "title": "Threats to validity",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 6 FAQ slides (PDF)\nZilch!\n Live R script\n restaurant_inspections.csv"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Measurement and DAGs",
    "section": "",
    "text": "The witch trial scene from Monty Python and the Holy Grail\n Chapter 5 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege.\n Chapter 5 in The Effect (Huntington-Klein 2021)\n\n\n\n\n\n Julia M. Rohrer, “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data” (Rohrer 2018) This will be posted on iCollege.\n Section 2 only (pp. 4–11) from Julian Schuessler and Peter Selb, “Graphical Causal Models for Survey Inference.” (Schuessler and Selb 2019) The PDF is available at SocArXiv.\n Chapters 6 and 7 in The Effect (Huntington-Klein 2021)\n\n\n\n\n\nThe example page on DAGs shows how to draw and analyze DAGs with both dagitty.net and R + ggdag"
  },
  {
    "objectID": "content/04-content.html#readings",
    "href": "content/04-content.html#readings",
    "title": "Measurement and DAGs",
    "section": "",
    "text": "The witch trial scene from Monty Python and the Holy Grail\n Chapter 5 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege.\n Chapter 5 in The Effect (Huntington-Klein 2021)\n\n\n\n\n\n Julia M. Rohrer, “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data” (Rohrer 2018) This will be posted on iCollege.\n Section 2 only (pp. 4–11) from Julian Schuessler and Peter Selb, “Graphical Causal Models for Survey Inference.” (Schuessler and Selb 2019) The PDF is available at SocArXiv.\n Chapters 6 and 7 in The Effect (Huntington-Klein 2021)\n\n\n\n\n\nThe example page on DAGs shows how to draw and analyze DAGs with both dagitty.net and R + ggdag"
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Measurement and DAGs",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nAbstraction, stretching, and validity\n\n\nCausal models\n\n\nPaths, doors, and adjustment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/04-content.html#videos",
    "href": "content/04-content.html#videos",
    "title": "Measurement and DAGs",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nAbstraction, stretching, and validity\nCausal models\nPaths, doors, and adjustment\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/04-content.html#in-class-stuff",
    "href": "content/04-content.html#in-class-stuff",
    "title": "Measurement and DAGs",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 4 FAQ slides (PDF)"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Regression and inference",
    "section": "",
    "text": "Chapters 3 and 4 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "Regression and inference",
    "section": "",
    "text": "Chapters 3 and 4 in The Effect (Huntington-Klein 2021)"
  },
  {
    "objectID": "content/02-content.html#recommended-readings",
    "href": "content/02-content.html#recommended-readings",
    "title": "Regression and inference",
    "section": "Recommended readings",
    "text": "Recommended readings\nLook through your notes on regression from your last stats class. Also, you can skim through these resources:\n\n 5.1–5.4 in ModernDive (Ismay and Kim 2019)\n 6.1–6.4 in ModernDive (Ismay and Kim 2019)\n 7.1–7.3 in OpenIntro Statistics (Diez, Barr, and Çetinkaya-Rundel 2017)\n 8.1 in OpenIntro Statistics (Diez, Barr, and Çetinkaya-Rundel 2017)\n\nWe’ll review all this regression stuff in the videos, so don’t panic if this all looks terrifying! Also, take advantage of the videos that accompany the OpenIntro chapters. And also, the OpenIntro chapters are heavier on the math—don’t worry if you don’t understand everything."
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Regression and inference",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nDrawing lines\n\n\nLines, Greek, and regression\n\n\nNull worlds and statistical significance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/02-content.html#videos",
    "href": "content/02-content.html#videos",
    "title": "Regression and inference",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nDrawing lines\nLines, Greek, and regression\nNull worlds and statistical significance\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/02-content.html#in-class-stuff",
    "href": "content/02-content.html#in-class-stuff",
    "title": "Regression and inference",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 2 FAQ slides (PDF)\nErrors vs. warnings vs. messages (i.e. what to do when R shows you red text)\nR Markdown examples:\n\nExample R Markdown file used as a code-through or step-by-step teaching document:\n\nLots of blog posts here\nJulia Silge, “Modeling human/computer interactions on Star Trek from #TidyTuesday with workflowsets”\nBob Rudis, “Some Covid Donuts To End The Week”\nHolger K. von Jouanne-Diedrich, “The “Youth Bulge” of Afghanistan: The Hidden Force behind Political Instability”\n\nExample R Markdown file used as a publicly-consumable document:\n\nClick on the “Manuscript” menu item at this site\nSee the Rmd file here\n\n\n\nHands-on R materials:\n\nRStudio.cloud project\nProject .zip file\nGapminder data\nLab slides 1: Markdown and universal writing (PDF)\nLab slides 2: Getting started with R and RStudio (PDF)\nLab slides 3: Data basics (PDF)\nLab slides 4: Visualize data with ggplot2 (PDF)\nLab slides 5: Transform data with dplyr (PDF)\n restaurant_inspections.csv"
  },
  {
    "objectID": "content/02-content.html#bayesian-statistics-resources",
    "href": "content/02-content.html#bayesian-statistics-resources",
    "title": "Regression and inference",
    "section": "Bayesian statistics resources",
    "text": "Bayesian statistics resources\nIn class I briefly mentioned the difference between frequentist and Bayesian statistics. You can see a bunch of additional resources and examples of these two approaches to statistics here. This huge blog post also shows how to do multilevel models with Bayesian models."
  },
  {
    "objectID": "assignment/weekly-check-in.html",
    "href": "assignment/weekly-check-in.html",
    "title": "Weekly check-in",
    "section": "",
    "text": "Every week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in this course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/final-project.html",
    "href": "assignment/final-project.html",
    "title": "Final project",
    "section": "",
    "text": "Evaluation research is tricky and costly. If you begin an intervention or launch a study prematurely, you can waste time and money—and potentially lives.\nEven if you have a well designed program with an impeccable logic model and a perfect DAG, you might discover (too late!) that you forgot to collect some critical variables or realize that your identification strategy will not work.\nFrom a more cynical perspective, you might (unethically) engage in the practice of p-hacking—running all sorts of different model specifications until you find the results you want, and then claim in your report that you had intended to run that model all along.\nOne increasingly popular method for (1) ensuring that your data and methods work before launching a study or intervention, and (2) declaring and committing to your hypotheses and methods and models before analyzing your data is to pre-register your research or evaluation. A pre-registered study contains all the background work—an introduction, literature review, theory, hypotheses, and proposed analysis—but without the actual data. Authors post their expectations and hypotheses publicly so they can be held publicly accountable for any deviations from their proposed design.1\nThe best preregistered studies use simulated data that has the same structure as the data that will be collected (i.e. same columns, sometimes the same correlations and relationships researchers expect to see in the collected data, etc.). Because there’s no data yet (or just fake data), you have more freedom when developing a preregistered study. You can experiment with different models, play with different approaches, manipulate data in different ways, and so on. If you realize that you need a new variable, or that you need to rearrange questions on a survey, or make any other kinds of changes, you can—you haven’t collected the data yet!\n(Additionally, using synthetic data is extremely useful if you’re working with proprietary or private data that you cannot make public. You can make a synthetic version of the real data instead; see this too.)\nOnce you finalize your plan and know all the data you need to collect, and once you’ve written out the different models you’ll run, all you have to do is collect the real data, plop it into your script (replacing the fake data you’d been using), and run the analysis script again to generate the actual, real results. In the results section, you get to either say “As predicted, we found…”, or “Contrary to expectations, we found that…”.\nFor your final project in this class, you will write a pre-registered analysis of a public or nonprofit social program that you’re interested in. You don’t need to worry about collecting data—you’ll create a synthetic dataset for your pre-analysis.\nYou will submit three things via iCollege:\nThis project is due by 11:59 PM on Monday, December 12, 2022.  No late work will be accepted.\nYou can either run the analysis in RStudio locally on your computer (highly recommended(!!), since you won’t have to worry about keeping all your work on RStudio’s servers), or use an RStudio.cloud project. You can make a copy of this RStudio.cloud project—it doesn’t have anything in it, but I have preinstalled all the packages we’ve used over the course of the semester, so you don’t have to."
  },
  {
    "objectID": "assignment/final-project.html#resources",
    "href": "assignment/final-project.html#resources",
    "title": "Final project",
    "section": "Resources",
    "text": "Resources\nMost importantly, do not hesitate to work with classmates. You all must choose different programs, but you can work in groups of up to 4 people on your own projects. Also, absolutely do not hesitate to ask me questions! I’m here to help!\nYou might find this evaluation (and its proposal) of a truancy program in the Provo School District in Utah helpful as an example for the first half of this assignment (program overview, theory, implementation, threats to validity, and outcomes). The PSD evaluation doesn’t have DAGs or fancy econometrics models like RCTs, diff-in-diff, RDD, IVs, or anything like that, so you can’t use it as an example of that part, but these should provide a good template for the program-specific sections. This is longer than expected for this class. I provide suggested word counts in the outline below.\n\n psd-proposal-2011\n psd-final-report-2012"
  },
  {
    "objectID": "assignment/final-project.html#suggested-outline",
    "href": "assignment/final-project.html#suggested-outline",
    "title": "Final project",
    "section": "Suggested outline",
    "text": "Suggested outline\nHere’s an outline of what you’ll need to do. You did lots of this work in your evaluation assignments. Please don’t just copy/paste those assignments as is into this final project—you’ll want to polish it up for this final report. You can download this as an RMarkdown file and change the text if you want. I’ve also included this as an RMarkdown file in the empty RStudio.cloud project.\n\n final-project-template.Rmd\n\n\n\nIntroduction\nDescribe the motivation for this evaluation, briefly describe the program to be evaluated, and explain why it matters for society. (≈150 words)\n\n\nProgram overview\nProvide in-depth background about the program. Include details about (1) when it was started, (2) why it was started, (3) what it was designed to address in society. If the program hasn’t started yet, explain why it’s under consideration. (≈300 words)\n\n\nProgram theory and implementation\n\nProgram theory and impact theory graph\nExplain and explore the program’s underlying theory. Sometimes programs will explain why they exist in a mission statement, but often they don’t and you have to infer the theory from what the program looks like when implemented. What did the program designers plan on occurring? Was this theory based on existing research? If so, cite it. (≈300 words)\nInclude a simple impact theory graph showing the program’s basic activities and outcomes. Recall from class and your reading that this is focused primarily on the theory and mechanisms, not on the implementation of the program.\n\n\nLogic model\nDescribe the program’s inputs, activities, outputs, and outcomes. Pay careful attention to how they are linked—remember that every input needs to flow into an activity and every output must flow out of an activity. (≈150 words)\nUse flowchart software to connect the inputs, activities, outputs, and outcomes and create a complete logic model. Include this as a figure.\n\n\n\nOutcome and causation\n\nMain outcome\nSelect one of the program’s outcomes to evaluate. Explain why you’ve chosen this (is it the most important? easiest to measure? has the greatest impact on society?) (≈50 words)\n\n\nMeasurement\nUsing the concept of the “ladder of abstraction” that we discussed in class (e.g. identifying a witch, measuring poverty, etc.), make a list of all the possible attributes of the outcome. Narrow this list down to 3-4 key attributes. Discuss how you decided to narrow the concepts and justify why you think these attributes capture the outcome. Then, for each of these attributes, answer these questions:\n\nMeasurable definition: How would you specifically define this attribute? (i.e. if the attribute is “reduced crime”, define it as “The percent change in crime in a specific neighborhood during a certain time frame” or something similar)\nIdeal measurement: How would you measure this attribute in an ideal world?\nFeasible measurement: How would you measure this given reality and given limitations in budget, time, etc.?\nMeasurement of program effect: How would to connect this measure to people in the program? How would you check to see if the program itself had an effect?\n\n(≈150 words in this section)\n\n\nCausal theory\nGiven your measurement approach, describe and draw a causal diagram (DAG) that shows how your program causes the outcome. Note that this is not the same thing as the logic model—you’ll likely have nodes in the DAG that aren’t related to the program at all (like socioeconomic status, gender, experience, or other factors). The logic model provides the framework for the actual implementation of your program and connects all the moving parts to the outcomes. The DAG is how you can prove causation with statistical approaches. (≈150 words)\n\n\nHypotheses\nMake predictions of your program’s effect. Declare what you think will happen. (≈50 words)\n\n\n\nData and methods\n\nIdentification strategy\nHow will you measure the actual program effect? Will you rely on an RCT? Differences-in-differences? Regression discontinuity? Instrumental variables? How does your approach account for selection bias and endogeneity? How does your approach isolate the causal effect of the program on the outcome?\nAlso briefly describe what kinds of threats to internal and external validity you face in your study.\n(≈300 words)\n\n\nData\nGiven your measurement approach, limits on feasibility, and identification strategy, describe the data you will use. Will you rely on administrative data collected by a government agency or nonprofit? Will you collect your own data? If so, what variables will you measure, and how? Will you conduct a survey or rely on outside observers or do something else? What does this data look like? What variables does it (or should it) include?\n(≈100 words)\n\n\n\nSynthetic analysis\nGenerate a synthetic (fake) dataset in R with all the variables you’ll need for the real life analysis. Analyze the data using your identification strategy. For instance:\n\nIf you’re relying on observational data, close all the backdoors with matching or inverse probability weighting, don’t adjust for colliders, and make a strong argument for isolation of the causal effect in the absence of treatment/control groups\nIf you’re doing an RCT, test the differences in means in the treatment and control groups (and follow all other best practices listed in the World Bank book, checking for balance across groups, etc.)\nIf you’re doing diff-in-diff, run a regression model with an interaction term to show the diff-in-diff\nIf you’re doing regression discontinuity, check for a jump in the outcome variable at the cutoff in the running variable\nIf you’re using instrumental variables, check the validity of your instrument and run a 2SLS model\n\nInclude robustness checks to ensure the validity of your effect (i.e. if you’re doing regression discontinuity, test different bandwidths and kernel types; etc.)\n(As many words as you need to fully describe your analysis and results)\n\n\nConclusion\nWhat would the findings from this analysis mean for your selected program? What would it mean if you found an effect? What would it mean if you didn’t find an effect? Why does any of this matter? (≈75 words)"
  },
  {
    "objectID": "assignment/final-project.html#footnotes",
    "href": "assignment/final-project.html#footnotes",
    "title": "Final project",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee the Center for Open Science’s directory of preregistrations, or AsPredicted list for examples of this in real life. Here’s one by me!↩︎"
  },
  {
    "objectID": "assignment/08-problem-set.html",
    "href": "assignment/08-problem-set.html",
    "title": "Problem set 8",
    "section": "",
    "text": "This assignment is a review of all the causal inference methods we’ve learned this semester: RCTs, matching and inverse probability weighting, diff-in-diff, RDD, and IVs. Refer to your past assignments and all the examples for guidance:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/08-problem-set.html#instructions",
    "href": "assignment/08-problem-set.html#instructions",
    "title": "Problem set 8",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-8.Rproj:  problem-set-8.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, broom, estimatr, modelsummary, MatchIt, rdrobust, rddensity, and haven. If you try to load one of those packages with library(tidyverse) or library(MatchIt), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 8” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 8.”)\nRename the R Markdown file named your-name_problem-set-8.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. You can remove any of the question text if you want.\nYou can definitely copy, paste, and adapt from other code in the document or the different example pages—don’t try to write everything from scratch!.\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/06-problem-set.html",
    "href": "assignment/06-problem-set.html",
    "title": "Problem set 6",
    "section": "",
    "text": "For this problem set, you’ll practice doing regression discontinuity analysis with simulated data from a hypothetical program. This example page will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/06-problem-set.html#instructions",
    "href": "assignment/06-problem-set.html#instructions",
    "title": "Problem set 6",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-6.Rproj:  problem-set-6.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, broom, rdrobust, rddensity, and modelsummary. If you try to load one of those packages with library(tidyverse) or library(rdrobust), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 6” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 6.”)\nRename the R Markdown file named your-name_problem-set-6.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold. Your job is to answer those questions. You don’t need to put your answers in bold or ALL CAPS or anything, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on regression discontinuity—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/04-problem-set.html",
    "href": "assignment/04-problem-set.html",
    "title": "Problem set 4",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but again, it’s mostly copying/pasting chunks of code and changing things.\nFor this problem set, you’ll practice running difference-in-differences analysis with R, both manually and with regression. This example will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/04-problem-set.html#instructions",
    "href": "assignment/04-problem-set.html#instructions",
    "title": "Problem set 4",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-4.Rproj:  problem-set-4.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, haven, and broom. If you try to load one of those packages with library(tidyverse) or library(haven), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 4” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 4.”)\nRename the R Markdown file named your-name_problem-set-4.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold (e.g. **What is the ATE?**). Your job is to answer those questions. You don’t need to put your answers in bold, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on diff-in-diff—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/03-problem-set.html",
    "href": "assignment/03-problem-set.html",
    "title": "Problem set 3",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but again, it’s mostly copying/pasting chunks of code and changing things.\nFor this problem set, you’ll practice analyzing RCTs and working with matching and inverse probability weighting. These two examples will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown this time (and from now on). You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/03-problem-set.html#instructions",
    "href": "assignment/03-problem-set.html#instructions",
    "title": "Problem set 3",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-3.Rproj:  problem-set-3.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, MatchIt, modelsummary, and patchwork. If you try to load one of those packages with library(tidyverse) or library(MatchIt), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 3” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 3.”)\nRename the R Markdown file named your-name_problem-set-3.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold (e.g. **What is the ATE?**). Your job is to answer those questions. You don’t need to put your answers in bold, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on RCTs and the example page on matching and IPW—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/02-problem-set.html",
    "href": "assignment/02-problem-set.html",
    "title": "Problem set 2",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but it’s mostly copying/pasting chunks of code and changing things."
  },
  {
    "objectID": "assignment/02-problem-set.html#getting-started",
    "href": "assignment/02-problem-set.html#getting-started",
    "title": "Problem set 2",
    "section": "Getting started",
    "text": "Getting started\nFor this problem set, you’ll practice running and interpreting regression models using data about penguins in Antarctica and data on food access and mortality in the US.\nYou’ll be doing all your R work in R Markdown this time (and from now on). You should use an RStudio Project to keep your files well organized (either on your computer or on RStudio.cloud). Either create a new project for this exercise only, or make a project for all your work in this class.\nYou’ll need to download these two CSV files and put them somewhere on your computer or upload them to RStudio.cloud—preferably in a folder named data in your project folder:\n\n penguins.csv\n food_health_politics.csv\n\nYou’ll also need to download this R Markdown file with a template for this problem set. Download that here and include it in your project:\n\n problem-set-2.Rmd\n\nIn the end, the structure of your project directory should look something like this:\nyour-project-name\n├── data\n│   ├── food_health_politics.csv\n│   └── penguins.csv\n├── your-project-name.Rproj\n└── your-name_problem-set-2.Rmd\nTo check that you put everything in the right places, you can download and unzip this file, which contains everything in the correct structure:\n\n problem-set-2.zip\n\nYou’ll need to make sure you have these packages installed on your computer: tidyverse and modelsummary. If you try to load one of those packages with library(tidyverse) or library(modelsummary), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 2” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 2.”)\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nRemember, if you’re struggling, please talk to me. Work with classmates too. Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/02-problem-set.html#instructions",
    "href": "assignment/02-problem-set.html#instructions",
    "title": "Problem set 2",
    "section": "Instructions",
    "text": "Instructions\nFor this problem set, we’re less interested in causal relationships and more interested in the mechanics of manipulating data and running regressions in R. We’ll start caring about identification and causal models in the next problem set. Because of this, don’t put too much causal weight into the interpretations of these different models—this is an actual case of correlation not implying causation.\nThe example for week 2 on regression will be incredibly helpful for this exercise. Reference it. Copy and paste from it liberally.\n\nRename the R Markdown file named your-name_problem-set-2.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. Fill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or from the regression example—don’t try to write everything from scratch!), and replace text in ALL CAPS with your own. (i.e. You’ll see a bunch of TYPE YOUR ANSWER HEREs. Type your answers there.). Again, you don’t need to type your answers in all caps."
  },
  {
    "objectID": "assignment/02-problem-set.html#turning-everything-in",
    "href": "assignment/02-problem-set.html#turning-everything-in",
    "title": "Problem set 2",
    "section": "Turning everything in",
    "text": "Turning everything in\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/01-problem-set.html",
    "href": "assignment/01-problem-set.html",
    "title": "Problem set 1",
    "section": "",
    "text": "Go the the example page for this week, “Welcome to R, RStudio, and the tidyverse”, and work through the different primers and videos in the four parts of the page.\nIt seems like there’s a lot on the page, but they’re short and go fairly quickly (especially as you get the hang of the syntax). Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck and want to skip some (or if it gets too easy), go right ahead and skip them!"
  },
  {
    "objectID": "assignment/01-problem-set.html#task-1-introduce-yourself-to-r-rstudio-and-the-tidyverse",
    "href": "assignment/01-problem-set.html#task-1-introduce-yourself-to-r-rstudio-and-the-tidyverse",
    "title": "Problem set 1",
    "section": "",
    "text": "Go the the example page for this week, “Welcome to R, RStudio, and the tidyverse”, and work through the different primers and videos in the four parts of the page.\nIt seems like there’s a lot on the page, but they’re short and go fairly quickly (especially as you get the hang of the syntax). Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck and want to skip some (or if it gets too easy), go right ahead and skip them!"
  },
  {
    "objectID": "assignment/01-problem-set.html#task-2-make-an-rstudio-project",
    "href": "assignment/01-problem-set.html#task-2-make-an-rstudio-project",
    "title": "Problem set 1",
    "section": "Task 2: Make an RStudio Project",
    "text": "Task 2: Make an RStudio Project\n\nUse either RStudio.cloud or RStudio on your computer (preferably RStudio on your computer! Follow these instructions to get started!) to create a new RStudio Project. Refer to the example page you read in Task 1 for instructions\nCreate a folder named “data” in the project folder you just made.\nDownload this CSV file and place it in that folder:\n\n cars.csv\n\nIn RStudio, go to “File” &gt; “New File…” &gt; “R Markdown…” and click “OK” in the dialog without changing anything.\nDelete all the placeholder text in that new file and replace it with this:\n---\ntitle: \"Problem set 1\"\nauthor: \"Put your name here\"\noutput: html_document\n---\n\n\n```{r load-libraries-data, warning=FALSE, message=FALSE}\nlibrary(tidyverse)\n\ncars &lt;- read_csv(\"data/cars.csv\")\n```\n\n\n\n# Learning R\n\nTell me that you worked through the primers and videos and examples at the example page for this week:\n\nWRITE SOMETHING HERE LIKE \"I did all the primers and had the time of my life!\" or whatever.\n\n\n# My first plots\n\nInsert a chunk below and use it to create a scatterplot (hint: `geom_point()`) with diplacement (`displ`) on the x-axis, city MPG (`cty`) on the y-axis, and with the points colored by drive (`drv`).\n\nPUT CHUNK HERE\n\nInsert a chunk below and use it to create a histogram (hint: `geom_histogram()`) with highway MPG (`hwy`) on the x-axis. Do not include anything on the y-axis (`geom_histogram()` will do that automatically for you). Choose an appropriate bin width. If you're brave, facet by drive (`drv`).\n\nPUT CHUNK HERE\n\n\n# My first data manipulation\n\nInsert a chunk below and use it to calculate the average city MPG (`cty`) by class of car (`class`). This won't be a plot---it'll be a table. Hint: use a combination of `group_by()` and `summarize()`.\n\nPUT CHUNK HERE\nSave the R Markdown file with some sort of name (without any spaces!)\nYour project folder should look something like this:"
  },
  {
    "objectID": "assignment/01-problem-set.html#task-3-work-with-r",
    "href": "assignment/01-problem-set.html#task-3-work-with-r",
    "title": "Problem set 1",
    "section": "Task 3: Work with R",
    "text": "Task 3: Work with R\n\nRemove the text that says “PUT CHUNK HERE” and insert a new R code chunk. Either type ctrl + alt + i on Windows, or ⌘ + ⌥ + i on macOS, or use the “Insert Chunk” menu:\n\n\n\n\n\n\n\n\n\n\n\nFollow the instructions for the three chunks of code.\nKnit your document as a Word file (or PDF if you’re brave and installed LaTeX). Use the “Knit” menu:\n\n\n\n\n\n\n\n\n\n\n\nUpload the knitted document to iCollege.\n🎉 Party! 🎉\n\n\n\n\n\n\n\nTip\n\n\n\nYou’ll be doing this same process for all your future problem sets. Each problem set will involve an R Markdown file. You can either create a new RStudio Project directory for all your work:\n\n\n\n\n\n\n\n\n\nOr you can create individual projects for each assignment and project:"
  },
  {
    "objectID": "assignment/01-eval-background-theory.html",
    "href": "assignment/01-eval-background-theory.html",
    "title": "Background and theory",
    "section": "",
    "text": "For your final project, you will conduct an evaluation for a social program of your choosing. In this assignment, you will explore the program’s background, history, purpose, and theory.\nIf you decide to use a different program for your final project, that’s okay! This assignment doesn’t have to be related to your final program, but it would be helpful—a more polished version of this assignment can be included as part of your final project."
  },
  {
    "objectID": "assignment/01-eval-background-theory.html#instructions",
    "href": "assignment/01-eval-background-theory.html#instructions",
    "title": "Background and theory",
    "section": "Instructions",
    "text": "Instructions\nYou need to complete the four sections listed below. Ideally you should type this in R Markdown and knit your document to HTML or Word or PDF, but you can also write in Word if you want (though your final project will need to be in R Markdown, and this would give you practice).1\nI’ve created an R Markdown template you can use here:  background-theory.zip. It’s also available on RStudio.cloud.\nYou can draw your impact theory and logic model charts by hand or with something like Diagrams.net, Lucidchart, or Creately. Export the image as a PNG, place it in the same directory as your R Markdown file, and include the image with Markdown.\nThe syntax for adding an image in Markdown is fairly simple. Importantly, it is not R code, so don’t try putting it in an R chunk. Just type this:\n![Image caption](/path/to/image.png)\nSubmit this assignment as a PDF or Word file on iCollege."
  },
  {
    "objectID": "assignment/01-eval-background-theory.html#assignment-outline",
    "href": "assignment/01-eval-background-theory.html#assignment-outline",
    "title": "Background and theory",
    "section": "Assignment outline",
    "text": "Assignment outline\n\n1: Program background and purpose\n(≈350 words)\nProvide in-depth background about the program. Include details about (1) when it was started, (2) why it was started, (3) what it was designed to address in society. If the program hasn’t started yet, explain why it’s under consideration. Make sure you cite your sources appropriately! (In the past, some students have just copied/pasted text from a program’s website; don’t do that! Describe and analyze the program’s background!)\n\n\n2: Program theory\n(≈400 words)\nExplain and explore the program’s underlying theory. Sometimes programs will explain why they exist in a mission statement, but often they don’t and you have to infer the theory from what the program looks like when implemented. What did the program designers plan on occurring? Was this theory based on existing research? If so, cite it.\nInclude a simple impact theory graph showing the program’s basic activities and outcomes. Recall from class and your reading that this is focused primarily on the theory and mechanisms, not on the implementation of the program.\n\n\n3: Logic model\nList every possible input, activity, output, and outcome for the program and provide a brief 1–2 sentence description of each.\n\nInputs\n\nSomething\nSomething else\n\n\n\nActivities\n\nSomething\nSomething else\n\n\n\nOutputs\n\nSomething\nSomething else\n\n\n\nOutcomes\n\nSomething\nSomething else\n\n\n\nDiagram\nUse flowchart software to connect the inputs, activities, outputs, and outcomes and create a complete logic model. Remember that inputs will always feed into activities, and that activities always produce outputs (that’s the whole purpose of an activity: convert an input to an output). Include this as a figure.\n\n\n\n4: Analysis\n(≈150 words)\nEvaluate how well the logic model relates to the program theory. Do the inputs, activities, and outputs have a logical, well-grounded connection to the intended outcomes? Under ideal conditions, would the components of the program lead to changes or lasting effects?"
  },
  {
    "objectID": "assignment/01-eval-background-theory.html#footnotes",
    "href": "assignment/01-eval-background-theory.html#footnotes",
    "title": "Background and theory",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd if you want to be super brave, try using R Markdown’s citation system!↩︎"
  },
  {
    "objectID": "assignment/02-eval-measurement.html",
    "href": "assignment/02-eval-measurement.html",
    "title": "Measurement",
    "section": "",
    "text": "For your final project, you will conduct an evaluation for a social program of your choosing. In this assignment, you will decide how to best measure two of the program’s outcomes.\nIf you decide to use a different program for your final project, that’s okay! This assignment doesn’t have to be related to your final program, but it would be extraordinarily helpful—a more polished version of this assignment can be included as part of your final project."
  },
  {
    "objectID": "assignment/02-eval-measurement.html#instructions",
    "href": "assignment/02-eval-measurement.html#instructions",
    "title": "Measurement",
    "section": "Instructions",
    "text": "Instructions\nYou need to complete the two sections listed below. Ideally you should type this in R Markdown and knit your document to HTML or Word or PDF, but you can also write in Word if you want (though your final project will need to be in R Markdown, and this would give you practice).1\nI’ve created an R Markdown template you can use here:  measurement.zip. It’s also available on RStudio.cloud.\nSubmit this assignment as a PDF or Word file on iCollege."
  },
  {
    "objectID": "assignment/02-eval-measurement.html#assignment-outline",
    "href": "assignment/02-eval-measurement.html#assignment-outline",
    "title": "Measurement",
    "section": "Assignment outline",
    "text": "Assignment outline\n\n1: Measurement and abstraction for full-day kindergarten\nRead this article about half-day vs. full-day kindergarten in Utah. The article is 10 years old, and half-day kindergarten still remains standard practice in most Utah school districts.\nPretend you are the administrator of the Optional Extended Day Kindergarten initiative. Based on the Salt Lake Tribune article (which provides hints throughout, and especially in one of the final paragraphs), and based on your own knowledge of educational outcomes, make a list of two (2) possible outcomes of the full-day kindergarten program.\nThen, for each of those two outcomes, do the following: Using the concept of the “ladder of abstraction” that we discussed in class (e.g. identifying a witch, measuring poverty, etc.), make a list of all the possible attributes of the outcome. Narrow this list down to 3–4 key attributes. Discuss how you decided to narrow the concepts and justify why you think these attributes capture the outcome. (≈100 words)\nThen, for each of those attributes, answer these questions:\n\nMeasurable definition: How would you specifically define this attribute? (i.e. if the attribute is “reduced crime”, define it as “The percent change in crime in a specific neighborhood during a certain time frame” or something similar)\nIdeal measurement: How would you measure this attribute in an ideal world?\nFeasible measurement: How would you measure this given reality and given limitations in budget, time, etc.?\nMeasurement of program effect: How would to connect this measure to people in the program? How would you check to see if the program itself had an effect?\n\n\n\n2: Measurement and abstraction for your program\nMake a list of two possible outcomes of your selected program. For each of those outcomes, make a list of all the possible attributes. Narrow this list down to 3–4 key attributes. Discuss how you decided to narrow the concepts and justify why you think these attributes capture the outcome. (≈100 words)\nThen, for each of those attributes, answer these questions:\n\nMeasurable definition: How would you specifically define this attribute? (i.e. if the attribute is “reduced crime”, define it as “The percent change in crime in a specific neighborhood during a certain time frame” or something similar)\nIdeal measurement: How would you measure this attribute in an ideal world?\nFeasible measurement: How would you measure this given reality and given limitations in budget, time, etc.?\nMeasurement of program effect: How would to connect this measure to people in the program? How would you check to see if the program itself had an effect?"
  },
  {
    "objectID": "assignment/02-eval-measurement.html#footnotes",
    "href": "assignment/02-eval-measurement.html#footnotes",
    "title": "Measurement",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd if you want to be super brave, try using R Markdown’s citation system!↩︎"
  },
  {
    "objectID": "assignment/03-eval-dag.html",
    "href": "assignment/03-eval-dag.html",
    "title": "Causal model",
    "section": "",
    "text": "For your final project, you will conduct an evaluation for a social program of your choosing. In this assignment, you will decide how to model the causal effect of your program on your primary outcome.\nIf you decide to use a different program for your final project, that’s okay! This assignment doesn’t have to be related to your final program, but it would be extraordinarily helpful—a more polished version of this assignment can be included as part of your final project."
  },
  {
    "objectID": "assignment/03-eval-dag.html#instructions",
    "href": "assignment/03-eval-dag.html#instructions",
    "title": "Causal model",
    "section": "Instructions",
    "text": "Instructions\nYou need to complete the three sections listed below. Ideally you should type this in R Markdown and knit your document to HTML or Word or PDF, but you can also write in Word if you want (though your final project will need to be in R Markdown, and this would give you practice).\nI’ve created an R Markdown template you can use here:  causal-model.zip. It’s also available on RStudio.cloud.\nSubmit this assignment as a PDF or Word file on iCollege."
  },
  {
    "objectID": "assignment/03-eval-dag.html#dag-i",
    "href": "assignment/03-eval-dag.html#dag-i",
    "title": "Causal model",
    "section": "1: DAG I",
    "text": "1: DAG I\nFind a news article that makes a causal claim and interpret that claim by drawing an appropriate diagram. The article likely won’t explain all the things the researchers controlled for, so you’ll need to create an ideal DAG. What should be included in the causal process to measure the effect of X on Y?\nExport the figure from dagitty and include it in your assignment, or use this code to draw the DAG with R:\n\nlibrary(tidyverse)\nlibrary(ggdag)\n\n# Remember that you can change the variable names here--they can be basically\n# anything, but cannot include spaces. The labels can have spaces. Adjust the\n# variable names (y, x2, etc) and labels (\"Outcome\", \"Something\", etc.) as\n# necessary.\nmy_dag &lt;- dagify(y ~ x1 + x2 + z,\n                 z ~ x1,\n                 x2 ~ x1 + z,\n                 labels = c(\"y\" = \"Outcome\",\n                            \"x1\" = \"Something\",\n                            \"x2\" = \"Something else\",\n                            \"z\" = \"Yet another thing\"),\n                 exposure = \"z\",\n                 outcome = \"y\")\n\n# If you set text = TRUE, you'll see the variable names in the DAG points\n# The `seed` argument makes it so that the random layout is the same every time\nggdag(my_dag, text = FALSE, use_labels = \"label\", seed = 1234) +\n  theme_dag()\n\n# If you want the treatment and outcomes colored differently,\n# replace ggdag() with ggdag_status()\nggdag_status(my_dag, text = FALSE, use_labels = \"label\", seed = 1234) +\n  theme_dag() +\n  theme(legend.position = \"bottom\")  # Move legend to bottom for fun\n\nSummarize the causal claim. Describe what the authors controlled for and what else you included in the DAG. Justify the inclusion of each node (point) and connection (line) in the graph. (≈150 words)\nIdentify all the frontdoor and backdoor paths between your exposure and outcome. What variables need to be controlled for / adjusted to close the backdoors? Did this happen in the study or article? (≈100 words)"
  },
  {
    "objectID": "assignment/03-eval-dag.html#dag-ii",
    "href": "assignment/03-eval-dag.html#dag-ii",
    "title": "Causal model",
    "section": "2: DAG II",
    "text": "2: DAG II\nFind a different news article with a causal claim and do the same thing as above.\nDraw and include a DAG.\nSummarize the causal claim. Describe what the authors controlled for and what else you included in the DAG. Justify the inclusion of each node (point) and connection (line) in the graph. (≈150 words)\nIdentify all the frontdoor and backdoor paths between your exposure and outcome. What variables need to be controlled for / adjusted to close the backdoors? Did this happen in the study or article? (≈100 words)"
  },
  {
    "objectID": "assignment/03-eval-dag.html#dag-for-your-program",
    "href": "assignment/03-eval-dag.html#dag-for-your-program",
    "title": "Causal model",
    "section": "3: DAG for your program",
    "text": "3: DAG for your program\nIdentify the outcome you care most about from your final project program. Draw a DAG that shows the causal effect of your program’s intervention on the outcome.\nSummarize the causal claim. Describe what needs to be controlled for and what else you included in the DAG. Justify the inclusion of each node (point) and connection (line) in the graph. (≈150 words)\nIdentify all the frontdoor and backdoor paths between your exposure and outcome. What variables need to be controlled for / adjusted to close the backdoors? How might you do this with your evaluation? (≈100 words)"
  },
  {
    "objectID": "assignment/04-eval-threats.html",
    "href": "assignment/04-eval-threats.html",
    "title": "Threats to validity",
    "section": "",
    "text": "You need to complete the “Assessing validity” section below. Ideally you should type this in R Markdown and knit your document to HTML or Word or PDF, but you can also write in Word if you want (though your final project will need to be in R Markdown, and this would give you practice).\nI’ve created an R Markdown template you can use here:  threats-validity.zip. It’s also available on RStudio.cloud.\nSubmit this assignment as a PDF or Word file on iCollege."
  },
  {
    "objectID": "assignment/04-eval-threats.html#instructions",
    "href": "assignment/04-eval-threats.html#instructions",
    "title": "Threats to validity",
    "section": "",
    "text": "You need to complete the “Assessing validity” section below. Ideally you should type this in R Markdown and knit your document to HTML or Word or PDF, but you can also write in Word if you want (though your final project will need to be in R Markdown, and this would give you practice).\nI’ve created an R Markdown template you can use here:  threats-validity.zip. It’s also available on RStudio.cloud.\nSubmit this assignment as a PDF or Word file on iCollege."
  },
  {
    "objectID": "assignment/04-eval-threats.html#internal-validity-scores",
    "href": "assignment/04-eval-threats.html#internal-validity-scores",
    "title": "Threats to validity",
    "section": "Internal validity scores",
    "text": "Internal validity scores\nOne helpful way to assess an evaluation’s internal validity is to systematically go through each possible threat and evaluate if the research design addresses it. For each of the 13 types of internal validity that we discussed in class, assign 1 point if the study addresses it and 0 points if it fails to do so. Add up the total points and assign the study a final internal validity score.\nNot all types of validity will apply to every study. Testing, for example, is only an issue if there is a pre-test and it involves a skill that could feasibly be enhanced by practicing the test. If a threat doesn’t apply, don’t give it a score.\n\nOmitted variable bias\n\nSelection\nAttrition\n\nTrends\n\nMaturation\nSecular trends\nSeasonality\nTesting\nRegression to the mean\n\nStudy calibration\n\nMeasurement error\nTime frame of study\n\nContamination\n\nHawthorne effects\nJohn Henry effects\nSpillovers\nIntervening events"
  },
  {
    "objectID": "assignment/04-eval-threats.html#assessing-validity",
    "href": "assignment/04-eval-threats.html#assessing-validity",
    "title": "Threats to validity",
    "section": "Assessing validity",
    "text": "Assessing validity\nYour textbook Impact Evaluation in Practice is full of short examples of real-world evaluations, experiments, and studies. For this assignment, you will assess the (1) internal validity, (2) external validity, and (3) construct validity for two of the examples from the book. If the summary in the book isn’t sufficient, you can skim through the original study for more details. The original studies can be found in the Content section of iCollege.\nYou will assess two (2) of these four studies. Pick whichever two seem the most interesting to you:\n\nThe effect of conditional cash transfers on education in Mexico (Box 4.2, p. 70)\n\nOriginal study: (Schultz 2004)\n\nThe impact of Sesame Street on school readiness (Box 5.1, p. 91)\n\nOriginal study: (Kearney and Levine 2015)\n\nThe effects of police deployment on crime in Argentina (Box 7.2, p. 135)\n\nOriginal study: (Di Tella and Schargrodsky 2004)\n\nEarly childhood development and migration in Jamaica (Box 9.5, p. 170)\n\nOriginal study: (Gertler et al. 2014)\n\n\nFor each of the two studies you choose, do the following:\n\nGo through the 13 types of internal validity and describe in 2–3 sentences how the study succeeds/fails to address each concern. Calculate a total internal validity score.\nDescribe any threats to external validity and assess how generalizable the findings are. (≈75 words)\nDescribe any threats to construct validity and assess if the researchers are measuring the thing they intended to measure. (≈75 words)"
  },
  {
    "objectID": "assignment/05-problem-set.html",
    "href": "assignment/05-problem-set.html",
    "title": "Problem set 5",
    "section": "",
    "text": "For this problem set, you’ll reproduce the results from one of the papers that you looked at in your threats to validity assignment:\nThe full published paper is posted on iCollege under “Content &gt; Validity assignment” (since you used the paper for that assignment). It’s not posted publicly here because of copyright reasons. The data comes from Di Tella and Schargrodsky’s data appendix available at their study’s AER webpage, and I’ve included it in the .zip file for the assignment.\nThis paper uses difference-in-differences to estimate the causal effect of increased policing on car thefts. Now that you know all about diff-in-diff, you can create their same results!\nThe answer key from Problem Set 4 (where you also did diff-in-diff) + this example page will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/05-problem-set.html#instructions",
    "href": "assignment/05-problem-set.html#instructions",
    "title": "Problem set 5",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-5.Rproj:  problem-set-5.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, haven, broom, fixest, and modelsummary. If you try to load one of those packages with library(tidyverse) or library(haven), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 5” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 5.”)\nRename the R Markdown file named your-name_problem-set-5.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold. Your job is to answer those questions. You don’t need to put your answers in bold or ALL CAPS or anything, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on diff-in-diff—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/07-problem-set.html",
    "href": "assignment/07-problem-set.html",
    "title": "Problem set 7",
    "section": "",
    "text": "For this problem set, you’ll practice using instrumental variables with both real and simulated data. This example page will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/07-problem-set.html#instructions",
    "href": "assignment/07-problem-set.html#instructions",
    "title": "Problem set 7",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-7.Rproj:  problem-set-7.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, broom, estimatr, and modelsummary. If you try to load one of those packages with library(tidyverse) or library(estimatr), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 7” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 7.”)\nRename the R Markdown file named your-name_problem-set-7.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions scattered throughout the document—your job is to answer those questions. You don’t need to put your answers in bold or ALL CAPS or anything, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on instrumental variables—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/09-problem-set.html",
    "href": "assignment/09-problem-set.html",
    "title": "Problem set 9",
    "section": "",
    "text": "This assignment will give you practice generating synthetic data and building in causal effects.\nThese two examples will be incredibly helpful:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "assignment/09-problem-set.html#instructions",
    "href": "assignment/09-problem-set.html#instructions",
    "title": "Problem set 9",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-9.Rproj:  problem-set-9.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, broom, ggdag, and scales. If you try to load one of those packages with library(tidyverse) or library(ggdag), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 9” on RStudio.cloud and complete the assignment in your browser without needing to install anything. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 9.”)\nRename the R Markdown file named your-name_problem-set-9.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. You can remove any of the question text if you want.\nYou can definitely copy, paste, and adapt from other code in the document or the example guide—don’t try to write everything from scratch!.\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in this course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Introduction and Causal Inference",
    "section": "",
    "text": "The syllabus, content, examples, and assignments pages for this class\n Chapter 1 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 1 and 2 in The Effect (Huntington-Klein 2021)\n DJ Patil, “What Makes a Radical and Revolutionary Technology?”\n\n(DJ Patil is the former Chief Data Scientist of the United States under President Obama. He gave this forum address at Brigham Young University on February 13, 2018.)\n\n Stephen Goldsmith, “Next Generation of Public Employees Must Understand Data and Policy”\n Hadley Wickham, “Data Science: How is it Different To Statistics?”"
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "Introduction and Causal Inference",
    "section": "",
    "text": "The syllabus, content, examples, and assignments pages for this class\n Chapter 1 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 1 and 2 in The Effect (Huntington-Klein 2021)\n DJ Patil, “What Makes a Radical and Revolutionary Technology?”\n\n(DJ Patil is the former Chief Data Scientist of the United States under President Obama. He gave this forum address at Brigham Young University on February 13, 2018.)\n\n Stephen Goldsmith, “Next Generation of Public Employees Must Understand Data and Policy”\n Hadley Wickham, “Data Science: How is it Different To Statistics?”"
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Introduction and Causal Inference",
    "section": "Slides",
    "text": "Slides\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: In the “Class details” video, I say that there are three books for the class: the World Bank evaluation book, ’Metrics Matter, and Causal Inference: The Mixtape. That’s not the case this semester, since we’re using the new The Effect book, which replaces both ’Metrics Matter and the Mixtape. So ignore that part of the video. The slides are updated with the correct books, though: see here.\n\n\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nData science and public service\n\n\nEvidence, evaluation, and causation (1)\n\n\nEvidence, evaluation, and causation (2)\n\n\nClass details\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/01-content.html#videos",
    "href": "content/01-content.html#videos",
    "title": "Introduction and Causal Inference",
    "section": "Videos",
    "text": "Videos\n\n\n\n\n\n\nWarning\n\n\n\nImportant!!: In the “Class details” video, I say that there are three books for the class: the World Bank evaluation book, ’Metrics Matter, and Causal Inference: The Mixtape. That’s not the case this semester, since we’re using the new The Effect book, which replaces both ’Metrics Matter and the Mixtape. So ignore that part of the video. The slides are updated with the correct books, though: see here.\n\n\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nData science and public service\nEvidence, evaluation, and causation (1)\nEvidence, evaluation, and causation (2)\nClass details\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/01-content.html#in-class-stuff",
    "href": "content/01-content.html#in-class-stuff",
    "title": "Introduction and Causal Inference",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 1 in-person slides (PDF)\n\nRStudio labs:\n\nRStudio.cloud project\nProject .zip file\nLab slides 1: Markdown and universal writing (PDF)\nLab slides 2: Getting started with R and RStudio (PDF)\nLab slides 3: Data basics (PDF)\nLab slides 4: Visualize data with ggplot2 (PDF)\nLab slides 5: Transform data with dplyr (PDF)"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Theories of change and logic models",
    "section": "",
    "text": "Chapter 2 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 2 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege.\n Chapter 3 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege."
  },
  {
    "objectID": "content/03-content.html#readings",
    "href": "content/03-content.html#readings",
    "title": "Theories of change and logic models",
    "section": "",
    "text": "Chapter 2 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 2 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege.\n Chapter 3 in Evaluation: A Systematic Approach (Rossi, Lipsey, and Henry 2019). This is available on iCollege."
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Theories of change and logic models",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nReproducibility\n\n\nProgram theories\n\n\nLogic models & results chains\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/03-content.html#videos",
    "href": "content/03-content.html#videos",
    "title": "Theories of change and logic models",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nReproducibility\nProgram theories\nLogic models & results chains\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "DAGs and potential outcomes",
    "section": "",
    "text": "Prologue and at least one of the four acts from This American Life, “Gardens of Branching Paths,” episode #691, January 10, 2020\n Chapter 3 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 8, 9, and 10 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on potential outcomes, ATEs, and CATEs shows how to use R to calculate ATEs and CATEs"
  },
  {
    "objectID": "content/05-content.html#readings",
    "href": "content/05-content.html#readings",
    "title": "DAGs and potential outcomes",
    "section": "",
    "text": "Prologue and at least one of the four acts from This American Life, “Gardens of Branching Paths,” episode #691, January 10, 2020\n Chapter 3 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 8, 9, and 10 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on potential outcomes, ATEs, and CATEs shows how to use R to calculate ATEs and CATEs"
  },
  {
    "objectID": "content/05-content.html#slides",
    "href": "content/05-content.html#slides",
    "title": "DAGs and potential outcomes",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\ndo()ing observational causal inference\n\n\nPotential outcomes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/05-content.html#videos",
    "href": "content/05-content.html#videos",
    "title": "DAGs and potential outcomes",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\ndo()ing observational causal inference\nPotential outcomes\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/05-content.html#in-class-stuff",
    "href": "content/05-content.html#in-class-stuff",
    "title": "DAGs and potential outcomes",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 5 FAQ slides (PDF)\n\n\nConfounding, unblocked\n\n\n\n\n\n\n\nConfounding, blocked\n\n\n\n\n\n\n\nMediation"
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Randomization and matching",
    "section": "",
    "text": "Andrew Heiss, “Causal Inference,” Chapter 10 in R for Political Data Science: A Practical Guide (2020) (Ignore the exercises!). Get the PDF here.\n Chapter 4 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 11 and 13 in The Effect (Huntington-Klein 2021). Focus especially on section 13.3 about standard errors. And skim chapter 11; it’s an overview of regression, which we reviewed in session 2, but it also applies the language of DAGs to regression, so look for that specifically as you read.\n Planet Money, “Moving To Opportunity?,” episode 937\n Aaron Carroll, “Workplace Wellness Programs Don’t Work Well. Why Some Studies Show Otherwise,” The Upshot, August 6, 2018\n\n\n\n\nThe example page on RCTs shows how to use R to analyze and estimate causal effects from RCTs\nThe example page on matching and inverse probability weighting shows how to use R to close backdoors, make adjustments, and find causal effects from observational data using matching and inverse probability weighting"
  },
  {
    "objectID": "content/07-content.html#readings",
    "href": "content/07-content.html#readings",
    "title": "Randomization and matching",
    "section": "",
    "text": "Andrew Heiss, “Causal Inference,” Chapter 10 in R for Political Data Science: A Practical Guide (2020) (Ignore the exercises!). Get the PDF here.\n Chapter 4 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapters 11 and 13 in The Effect (Huntington-Klein 2021). Focus especially on section 13.3 about standard errors. And skim chapter 11; it’s an overview of regression, which we reviewed in session 2, but it also applies the language of DAGs to regression, so look for that specifically as you read.\n Planet Money, “Moving To Opportunity?,” episode 937\n Aaron Carroll, “Workplace Wellness Programs Don’t Work Well. Why Some Studies Show Otherwise,” The Upshot, August 6, 2018\n\n\n\n\nThe example page on RCTs shows how to use R to analyze and estimate causal effects from RCTs\nThe example page on matching and inverse probability weighting shows how to use R to close backdoors, make adjustments, and find causal effects from observational data using matching and inverse probability weighting"
  },
  {
    "objectID": "content/07-content.html#slides",
    "href": "content/07-content.html#slides",
    "title": "Randomization and matching",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nThe magic of randomization\n\n\nHow to analyze RCTs\n\n\nThe “gold” standard\n\n\nAdjustment with matching\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/07-content.html#videos",
    "href": "content/07-content.html#videos",
    "title": "Randomization and matching",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nThe magic of randomization\nHow to analyze RCTs\nThe “gold” standard\nAdjustment with matching\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/07-content.html#in-class-stuff",
    "href": "content/07-content.html#in-class-stuff",
    "title": "Randomization and matching",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 7 FAQ slides (PDF)\nIn-class .zip file\nRStudio.cloud project\n\nOther helpful resources:\n\n“The Impact of Mask Distribution and Promotion on Mask Uptake and COVID-19 in Bangladesh”\nMacartan Humphreys, “I saw your RCT and I have some worries! FAQs”\nDarren Dahly, “Out of balance: A perspective on covariate adjustment in randomized experiments”\nBayesian stats and decison making\nStandard errors\nUnobserved confounding and sensitivity analysis"
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Difference-in-differences II",
    "section": "",
    "text": "This session is a continuation of session 8."
  },
  {
    "objectID": "content/09-content.html#readings",
    "href": "content/09-content.html#readings",
    "title": "Difference-in-differences II",
    "section": "",
    "text": "This session is a continuation of session 8."
  },
  {
    "objectID": "content/09-content.html#in-class-stuff",
    "href": "content/09-content.html#in-class-stuff",
    "title": "Difference-in-differences II",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nSession 9 FAQ slides (PDF)\nSession 8 R code (from last week) (on RStudio.cloud)\n\nAnd here are some useful blog posts and examples of the stuff we talked about today:\n\nHow random effects work\nTWFE diagnostics\nSensitivity analysis for unobserved confounding"
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Instrumental variables I",
    "section": "",
    "text": "Chapter 5 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 19 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on instrumental variables shows how to use R to analyze and estimate causal effects with instrumental variables"
  },
  {
    "objectID": "content/11-content.html#readings",
    "href": "content/11-content.html#readings",
    "title": "Instrumental variables I",
    "section": "",
    "text": "Chapter 5 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 19 in The Effect (Huntington-Klein 2021)\n\n\n\n\nThe example page on instrumental variables shows how to use R to analyze and estimate causal effects with instrumental variables"
  },
  {
    "objectID": "content/11-content.html#slides",
    "href": "content/11-content.html#slides",
    "title": "Instrumental variables I",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nEndogeneity and exogeneity\n\n\nInstruments\n\n\nUsing instruments\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/11-content.html#videos",
    "href": "content/11-content.html#videos",
    "title": "Instrumental variables I",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nEndogeneity and exogeneity\nInstruments\nUsing instruments\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/11-content.html#in-class-stuff",
    "href": "content/11-content.html#in-class-stuff",
    "title": "Instrumental variables I",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nWeek 11 FAQ slides (PDF)\nWeek 11 R code (on RStudio.cloud)"
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Choosing and planning ethical evaluations",
    "section": "",
    "text": "“Generating random numbers”\n “The ultimate guide to generating synthetic data for causal inference”\n Paul Hünermund and Beyers Louw, “On the Nuisance of Control Variables in Regression Analysis” (Hünermund and Louw 2020) (click on the PDF link in the right sidebar)\n “Types of Evaluation,” National Center for HIV/AIDS, Viral Hepatitis, STD, and TB Prevention, Centers for Disease Control (CDC)\n Chapters 11–13 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 15 in The Effect (Huntington-Klein 2021) (skim this)"
  },
  {
    "objectID": "content/13-content.html#readings",
    "href": "content/13-content.html#readings",
    "title": "Choosing and planning ethical evaluations",
    "section": "",
    "text": "“Generating random numbers”\n “The ultimate guide to generating synthetic data for causal inference”\n Paul Hünermund and Beyers Louw, “On the Nuisance of Control Variables in Regression Analysis” (Hünermund and Louw 2020) (click on the PDF link in the right sidebar)\n “Types of Evaluation,” National Center for HIV/AIDS, Viral Hepatitis, STD, and TB Prevention, Centers for Disease Control (CDC)\n Chapters 11–13 in Impact Evaluation in Practice (Gertler et al. 2016)\n Chapter 15 in The Effect (Huntington-Klein 2021) (skim this)"
  },
  {
    "objectID": "content/13-content.html#slides",
    "href": "content/13-content.html#slides",
    "title": "Choosing and planning ethical evaluations",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroduction\n\n\nTypes of evaluations\n\n\nModel- and design-based inference\n\n\nEthics and open science\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of special slide-specific commands."
  },
  {
    "objectID": "content/13-content.html#videos",
    "href": "content/13-content.html#videos",
    "title": "Choosing and planning ethical evaluations",
    "section": "Videos",
    "text": "Videos\nVideos for each section of the lecture are available at this YouTube playlist.\n\nIntroduction\nTypes of evaluations\nModel- and design-based inference\nEthics and open science\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "content/13-content.html#in-class-stuff",
    "href": "content/13-content.html#in-class-stuff",
    "title": "Choosing and planning ethical evaluations",
    "section": "In-class stuff",
    "text": "In-class stuff\nHere are all the materials we’ll use in class:\n\nWeek 13 FAQ slides (PDF)\n Live R script"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "Each class session has a set of required readings that you should complete before watching the lecture.\nEvery class session also has a YouTube playlist of short recorded videos for each of the lecture sections. The lecture slides are special HTML files made with the R package xaringan (R can do so much!). On each class session page you’ll see buttons for opening the presentation in a new tab or for downloading a PDF of the slides in case you want to print them or store them on your computer:\n\n View all slides in new window  Download PDF of all slides\n\nThe slides are also embedded on each page. You can click in the slides and navigate through them with ← and →. If you type ? (or shift + /) while viewing the slides you can see a list of slide-specific commands (like f for fullscreen or p for presenter mode if you want to see my notes)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Health Policy Methods\n        ",
    "section": "",
    "text": "Health Policy Methods\n        \n        \n            Combine research design, causal inference, and econometric tools to measure the effects of social programs\n        \n        \n            HPM 587 • Spring 2024Jacob WallaceYale University\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\nInstructor\n\n   Dr. Jacob Wallace\n   60 College St\n   jacob.wallace@yale.edu\n   jwswallace\n   Schedule an appointment\n\n\n\nCourse details\n\n   Thursdays\n   January–April 30, 2024\n   4:30–7:00 PM\n   Winslow Auditorium, LEPH\n   Slack\n\n\n\nContacting me\nE-mail and Slack are the best ways to get in contact with me. I will try to respond to all course-related e-mails and Slack messages within 24 hours (really), but also remember that life can be busy and chaotic for everyone (including me!), so if I don’t respond right away, don’t worry!"
  },
  {
    "objectID": "jacobAssignments/02-problem-set-new.html",
    "href": "jacobAssignments/02-problem-set-new.html",
    "title": "Problem set 2",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but it’s mostly copying/pasting chunks of code and changing things."
  },
  {
    "objectID": "jacobAssignments/02-problem-set-new.html#getting-started",
    "href": "jacobAssignments/02-problem-set-new.html#getting-started",
    "title": "Problem set 2",
    "section": "Getting started",
    "text": "Getting started\nFor this problem set, you’ll practice running and interpreting regression models using data about penguins in Antarctica and data on food access and mortality in the US.\nYou’ll be doing all your R work in R Markdown this time (and from now on). You should use an RStudio Project to keep your files well organized (either on your computer or on RStudio.cloud). Either create a new project for this exercise only, or make a project for all your work in this class.\nYou’ll need to download these two CSV files and put them somewhere on your computer or upload them to RStudio.cloud—preferably in a folder named data in your project folder:\n\n penguins.csv\n food_health_politics.csv\n\nYou’ll also need to download this R Markdown file with a template for this problem set. Download that here and include it in your project:\n\n problem-set-2.Rmd\n\nIn the end, the structure of your project directory should look something like this:\nyour-project-name\n├── data\n│   ├── food_health_politics.csv\n│   └── penguins.csv\n├── your-project-name.Rproj\n└── your-name_problem-set-2.Rmd\nTo check that you put everything in the right places, you can download and unzip this file, which contains everything in the correct structure:\n\n problem-set-2.zip\n\nYou’ll need to make sure you have these packages installed on your computer: tidyverse and modelsummary. If you try to load one of those packages with library(tidyverse) or library(modelsummary), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 2” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 2.”)\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nRemember, if you’re struggling, please talk to me. Work with classmates too. Don’t suffer in silence!"
  },
  {
    "objectID": "jacobAssignments/02-problem-set-new.html#instructions",
    "href": "jacobAssignments/02-problem-set-new.html#instructions",
    "title": "Problem set 2",
    "section": "Instructions",
    "text": "Instructions\nFor this problem set, we’re less interested in causal relationships and more interested in the mechanics of manipulating data and running regressions in R. We’ll start caring about identification and causal models in the next problem set. Because of this, don’t put too much causal weight into the interpretations of these different models—this is an actual case of correlation not implying causation.\nThe example for week 2 on regression will be incredibly helpful for this exercise. Reference it. Copy and paste from it liberally.\n\nRename the R Markdown file named your-name_problem-set-2.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. Fill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or from the regression example—don’t try to write everything from scratch!), and replace text in ALL CAPS with your own. (i.e. You’ll see a bunch of TYPE YOUR ANSWER HEREs. Type your answers there.). Again, you don’t need to type your answers in all caps."
  },
  {
    "objectID": "jacobAssignments/02-problem-set-new.html#turning-everything-in",
    "href": "jacobAssignments/02-problem-set-new.html#turning-everything-in",
    "title": "Problem set 2",
    "section": "Turning everything in",
    "text": "Turning everything in\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "jacobAssignments/04-problem-set-new.html",
    "href": "jacobAssignments/04-problem-set-new.html",
    "title": "Problem set 4",
    "section": "",
    "text": "Note\n\n\n\nIMPORTANT: This looks like a lot of work, but again, it’s mostly copying/pasting chunks of code and changing things.\nFor this problem set, you’ll practice running difference-in-differences analysis with R, both manually and with regression. This example will be incredibly useful for you:\nYou’ll be doing all your R work in R Markdown. You can download a zipped file of a pre-made project here:\nAnd as always, if you’re struggling, please talk to me. Work with classmates too (especially for this assignment!). Don’t suffer in silence!"
  },
  {
    "objectID": "jacobAssignments/04-problem-set-new.html#instructions",
    "href": "jacobAssignments/04-problem-set-new.html#instructions",
    "title": "Problem set 4",
    "section": "Instructions",
    "text": "Instructions\n\nIf you’re using R on your own computer, download this file, unzip it, and double click on the file named problem-set-4.Rproj:  problem-set-4.zip\nYou’ll need to make sure you have these packages installed on your computer: tidyverse, haven, and broom. If you try to load one of those packages with library(tidyverse) or library(haven), etc., and R gives an error that the package is missing, use the “Packages” panel in RStudio to install it.\n(Alternatively, you can open the project named “Problem Set 4” on RStudio.cloud and complete the assignment in your browser without needing to install anything. If you don’t have access to the class RStudio.cloud account, please let me know as soon as possible. This link should take you to the project—if it doesn’t, log in and look for the project named “Problem Set 4.”)\nRename the R Markdown file named your-name_problem-set-4.Rmd to something that matches your name and open it in RStudio.\nComplete the tasks given in the R Markdown file. There are questions marked in bold (e.g. **What is the ATE?**). Your job is to answer those questions. You don’t need to put your answers in bold, and you can remove the question text if you want.\nFill out code in the empty chunks provided (you can definitely copy, paste, and adapt from other code in the document or the example page on diff-in-diff—don’t try to write everything from scratch!).\nYou’ll need to insert your own code chunks. Rather than typing them by hand (that’s tedious!), use the “Insert” button at the top of the editing window, or press ⌥ + ⌘ + I on macOS, or ctrl + alt + I on Windows.\n\n\n\n\n\n\n\n\n\nRemember that you can run an entire chunk by clicking on the green play arrow in the top right corner of the chunk. You can also run lines of code line-by-line if you place your cursor on some R code and press ⌘ + enter (for macOS users) or ctrl + enter (for Windows users).\nMake sure you run each chunk sequentially. If you run a chunk in the middle of the document without running previous ones, it might not work, since previous chunks might do things that later chunks depend on.\nWhen you’re all done, click on the “Knit” button at the top of the editing window and create a Word or PDF version (if you’ve installed tinytex) of your document. Upload that file to iCollege. Do not upload a knitted HTML file (they don’t on iCollege)."
  },
  {
    "objectID": "jacobAssignments/index.html",
    "href": "jacobAssignments/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "jacobAssignments/index.html#weekly-check-in",
    "href": "jacobAssignments/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in this course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "jacobAssignments/index.html#problem-sets",
    "href": "jacobAssignments/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "jacobAssignments/index.html#evaluation-assignments",
    "href": "jacobAssignments/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "jacobAssignments/index.html#exams",
    "href": "jacobAssignments/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "jacobAssignments/index.html#final-project",
    "href": "jacobAssignments/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "news/2022-08-08_welcome.html",
    "href": "news/2022-08-08_welcome.html",
    "title": "Welcome to class!",
    "section": "",
    "text": "← News\n\n\n\nHello everyone!\nI’m Andrew Heiss, your professor for PMAP 8521 (Evaluation Research) this fall, and I’m so excited for the class! In this class you’ll learn all about causal inference, or how to legally claim causation with statistics. In your past stats courses you were always taught “correlation isn’t causation,” which is mostly true, except when it’s not. In this class you’ll get to legitimately make causal claims.\nWe’ll cover fun tools like directed acyclic graphs (DAGs), randomized controlled trials, difference-in-differences analysis, regression discontinuity analysis, and instrumental variables. You’ll also learn the statistical language R, which is free (which means you can keep using it after you graduate and not have to pay for really really expensive SPSS or Stata licenses). I’ve had former students get jobs because of the R part of this class—tons of organizations are looking for R skills nowadays.\nI have a few important announcements before class:\n\nWe are meeting in person, but as you’ll see in the syllabus (see the “Masking and vaccines” section there, I’m trying to take as many precautions as possible given the rapid spread of the BA.5 variant. For instance…\n…I’ve made the course a flipped course, which means you’ll do all the readings and watch the lectures on YouTube before class on Mondays. We’ll spend our class time answering questions, doing activities, and learning a lot of R together. This means that the bulk of the course material is fully online and asynchronous.\nBefore class, I’d love to get to know each you a little first, so I’ve created a quick survey to fill out. I’ve sent you a link to it via e-mail. Please take it at your earliest convenience.\nThe entire course is available at a special class website at https://evalf22.classes.andrewheiss.com/. Bookmark this site—it’ll be your best friend for the next semester. I only use iCollege for collecting your assignments, posting answer keys, posting a couple scanned book chapters, and offering the two exams (since it’s password protected). This website is the official source of dates and all other class information. Because it’s not part of iCollege, you’ll be able to reference it even after you graduate and lose access to GSU resources. You can even share it with others—it’s just a website!\nPlease read the main explanatory pages at the course website at your earliest convenience. The instructions and expectations for the class are divided across different pages, all accessible from the menu bar at the top of the site. Please read the main pages for the syllabus, schedule, content, assignments, and examples.\nWe’re using zero physical textbooks in this class. Every reading and book and piece of software in this class is 100% free (see the syllabus for more information about that).\n\nQuick background about me: I’m an assistant professor here at the Andrew Young School, where I’ve been teaching MPA/MPP microeconomics, program evaluation, and data visualization. I moved here from Utah in 2019, where I was a visiting professor of public management at the Marriott School of Business at Brigham Young University (BYU). While at BYU, I taught microeconomics, statistics, and data visualization (basically the same stuff I’m teaching now). I finished my PhD in public policy and political science from Duke in 2017, and before then I finished my MPA in nonprofit management from BYU in 2012.\nWhen I’m not teaching stats and evaluation, I research international nonprofits and political science. And when I’m not teaching or researching, I’m normally chilling at my house with my 6 (!!) kids (see https://www.heissatopia.com/ for photos and hilarious stories).\nAgain, I’m really excited to get started next week. This fall semester should be a blast!"
  },
  {
    "objectID": "news/2022-08-21_first-day.html",
    "href": "news/2022-08-21_first-day.html",
    "title": "Plan for the first day of class",
    "section": "",
    "text": "← News\n\n\n\nHi everyone!\nTomorrow’s the first day of class! Exciting!\nBeyond hoping that everyone is wearing a mask, I’ve structured the class in way that limits our exposure to each other as much as possible. As noted in the syllabus (https://evalf22.classes.andrewheiss.com/syllabus.html#course-structure), we’re using a flipped classroom this semester. What this means in practice is that you’ll do all the readings and watch asynchronous lecture videos before class meets on Mondays.\nOur in-person time will not involve lectures. Instead, it’ll be a more hands-on lab for working with R and answering the questions that come up from doing the readings and watching the lectures. That’s the point of the weekly check-in assignment (https://evalf22.classes.andrewheiss.com/assignment/weekly-check-in.html)—the only way this in-person time will be effective is if you do the readings + videos and ask questions in the weekly check-in.\nThe videos for the first day of class are live and ready to watch at https://evalf22.classes.andrewheiss.com/content/01-content.html (along with the readings). If possible, please watch them (and do the readings) before class on Monday so that we can start with the lab-like in-person time and get a good solid introduction to R and RStudio + answer the questions you have from the first session’s materials.\nIdeally, please try to submit the first weekly check-in on iCollege by tomorrow too so that we can have some good Q&A time during our in-person time. BUT no worries if not!\nIf you don’t have time to get through the materials before the first day, that’s totally fine—you can do it later and there’s no late penalty or anything for the first week, given that it is the first day of classes. But if you can, let’s get started!"
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "News",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\nMonday August 22, 2022 at 2:52 PM\n\n\nHow to reach out for help\n\n\nadvice\n\n\n\n\nSunday August 21, 2022 at 9:05 PM\n\n\nPlan for the first day of class\n\n\ngetting started\n\n\n\n\nMonday August 15, 2022 at 3:31 PM\n\n\nAnnouncements and updates\n\n\ngetting started\n\n\n\n\nMonday August 15, 2022 at 2:33 PM\n\n\nImportant R stuff\n\n\ngetting started\n\n\n\n\nMonday August 15, 2022 at 2:21 PM\n\n\nWelcome to class!\n\n\ngetting started\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\nSubscribe!\n\n\n\nYou can use a feed reader like Feedly or use an RSS-to-email service like Blogtrottr to subscribe to these updates and messages. I’ll also e-mail out links to them when there are new updates.\n\n\n\n RSS"
  },
  {
    "objectID": "resource/citations.html",
    "href": "resource/citations.html",
    "title": "Citations and bibliography",
    "section": "",
    "text": "You can download a BibTeX file of all the non-web-based readings in the course:\n\n references.bib\n\nYou can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online."
  },
  {
    "objectID": "resource/exam1.html",
    "href": "resource/exam1.html",
    "title": "Things you should know for Exam 1",
    "section": "",
    "text": "You should understand…\n\n…the difference between experimental research and observational research\n…the sometimes conflicting roles of science and intuition in public administration and policy\n…the difference between the various types of evaluations and how they target specific parts of a logic model\n…the difference between identifying correlation (math) and identifying causation (philosophy and theory)\n…what it means for a relationship to be causal"
  },
  {
    "objectID": "resource/exam1.html#evidence-causation-and-evaluation",
    "href": "resource/exam1.html#evidence-causation-and-evaluation",
    "title": "Things you should know for Exam 1",
    "section": "",
    "text": "You should understand…\n\n…the difference between experimental research and observational research\n…the sometimes conflicting roles of science and intuition in public administration and policy\n…the difference between the various types of evaluations and how they target specific parts of a logic model\n…the difference between identifying correlation (math) and identifying causation (philosophy and theory)\n…what it means for a relationship to be causal"
  },
  {
    "objectID": "resource/exam1.html#regression-and-inference",
    "href": "resource/exam1.html#regression-and-inference",
    "title": "Things you should know for Exam 1",
    "section": "Regression and inference",
    "text": "Regression and inference\nYou should understand…\n\n…the difference between correlation coefficients and regression coefficients\n…the difference between outcome/response/dependent and explanatory/predictor/independent variables\n…the two purposes of regression\n…what each of the components in a regression equation stand for, in both “flavors” of notation:\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\) for the statistical flavor\n\\(y = \\alpha + \\beta x_1 + \\gamma x_2 + \\epsilon\\) for the econometrics flavor\n\n…how sliders and switches work as metaphors for regression coefficients\n…what it means to hold variables constant (or to control for variables)\n…the different elements of the grammar of graphics and be able to identify how variables are encoded in a graph (i.e. how columns in a dataset can be represented through x/y coordinates, through color, through size, through fill, etc.)\n\nYou should be able to…\n\n…write and interpret R code that calculates summary statistics for groups (i.e. group_by() %&gt;% summarize())\n…write and interpret R code that builds linear models (i.e. lm())\n…interpret regression coefficients\n…interpret other regression diagnostics like \\(R^2\\)\n…use the %&gt;% pipe in R to chain functions together\n…use ggplot() to visualize data\n\nHelpful resources:\n\n Garrett Grolemund and Hadley Wickham, R for Data Science\n Kieran Healy, “How ggplot works,” chapter 3 in Data Visualization: A Practical Introduction"
  },
  {
    "objectID": "resource/exam1.html#theories-of-change-and-measurement",
    "href": "resource/exam1.html#theories-of-change-and-measurement",
    "title": "Things you should know for Exam 1",
    "section": "Theories of change and measurement",
    "text": "Theories of change and measurement\nYou should understand…\n\n…how to describe a program’s theory of change\n…the difference between inputs, activities, outputs, and outcomes\n…the elements of a program’s impact theory: causes (activities) linked to effects (outcomes)\n…the elements of a program’s logic model: the explicit links between all its inputs, activities, outputs, and outcomes\n…the difference between implicit and articulated program theories\n…the purpose of smaller-scale mechanism testing\n…how indicators can be measured at different levels of abstraction\n…what makes an indicator a good indicator\n\nYou should be able to…\n\n…identify a program’s underlying theory based on its mission statement\n…draw a program impact theory chart that links activities to outcomes\n…draw a program logic model that links inputs to activities to outputs to outcomes\n…identify the most central elements of a potential outcome measurement"
  },
  {
    "objectID": "resource/exam1.html#counterfactuals-and-dags",
    "href": "resource/exam1.html#counterfactuals-and-dags",
    "title": "Things you should know for Exam 1",
    "section": "Counterfactuals and DAGs",
    "text": "Counterfactuals and DAGs\nYou should understand…\n\n…how a causal model encodes our understanding of a causal process\n…how to identify front door and back door paths between treatment/exposure and outcome\n…why we avoid closing front door paths\n…why we close back door paths\n…why adjusting for colliders can distort causal effects\n…the difference between logic models and DAGs\n…the difference between individual level causal effects, average treatment effects (ATE), conditional average treatment effect (CATE), average treatment on the treated effects (ATT), and average treatment on the untreated (ATU)\n…what the fundamental problem of causal inference is and how we can attempt to address it\n\nYou should be able to…\n\n…draw a possible DAG for a given causal relationship\n…identify all pathways between treatment/exposure and outcome\n…identify which nodes in the DAG need to be adjusted for (or closed)\n…identify colliders (which should not be adjusted for)\n\nHelpful resources:\n\n Malcom Barrett, “An Introduction to Directed Acyclic Graphs”\n Malcom Barrett, “An Introduction to ggdag”\n Judea Pearl, “A Crash Course in Good and Bad Control”: A quick summary of back doors, front doors, confounders, colliders, and when to control/not control for DAG nodes\n Causal Inference Bootcamp, “Average Treatment Effects,” Duke University\n Causal Inference Bootcamp, “Unit Level Effects,” Duke University\n Causal Inference Bootcamp, “Conditional Average Treatment Effects,” Duke University\n Causal Inference Bootcamp, “Counterfactuals,” Duke University\n Neel Ocean, “Understanding Selection Bias”: explanation of how to identify selection bias from the ATT and the ATE, with an explanation of how ATE = ATT + selection bias under the potential outcomes framework\n Paul Hünermund, “Sample Selection vs. Selection Into Treatment”"
  },
  {
    "objectID": "resource/exam1.html#threats-to-validity",
    "href": "resource/exam1.html#threats-to-validity",
    "title": "Things you should know for Exam 1",
    "section": "Threats to validity",
    "text": "Threats to validity\nYou should understand…\n\n…what it means when a study has internal validity and know how to identify the major threats to internal validity, including: omitted variable bias (selection and attrition), trend issues (maturation, secular trends, seasonality, testing, regression to the mean), study calibration issues (measurement error, time frame of study), and contamination issues (Hawthorne effects, John Henry effects, spillovers, and intervening events)\n…why selection bias is the most pernicious and difficult threat to internal validity and how we can account for it\n…what it means when a study has external validity\n…what it means when the measures used in a study have construct validity\n…what it means when the analysis used in a study has statistical conclusion validity\n\nYou should be able to…\n\n…identify existing and potential threats to validity in a study\n…suggest ways of addressing these threats\n\nHelpful resources:\n\nReally, just google “threats to internal validity” or “threats to external validity” and you’ll find a billion different slide decks, articles, and lessons about these. They’re a pretty standard part of any research design class."
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Resources",
    "section": "",
    "text": "I have included a bunch of extra resources and guides related to causal inference, program evaluation, R, data, and other relevant topics. Enjoy!"
  },
  {
    "objectID": "resource/markdown.html",
    "href": "resource/markdown.html",
    "title": "Using Markdown",
    "section": "",
    "text": "Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)"
  },
  {
    "objectID": "resource/markdown.html#basic-markdown-formatting",
    "href": "resource/markdown.html#basic-markdown-formatting",
    "title": "Using Markdown",
    "section": "Basic Markdown formatting",
    "text": "Basic Markdown formatting\n\n\n\n\n\n\n\n\n\n\nType…\n\n\n…or…\n\n\n…to get\n\n\n\n\n\n\nSome text in a paragraph.\nMore text in the next paragraph. Always\nuse empty lines between paragraphs.\n\n\n\n\n\nSome text in a paragraph.\n\n\nMore text in the next paragraph. Always use empty lines between paragraphs.\n\n\n\n\n\nItalic\n\n\nItalic\n\n\nItalic\n\n\n\n\nBold\n\n\nBold\n\n\nBold\n\n\n\n\n# Heading 1\n\n\n\n\n\nHeading 1\n\n\n\n\n\n## Heading 2\n\n\n\n\n\nHeading 2\n\n\n\n\n\n### Heading 3\n\n\n\n\n\nHeading 3\n\n\n\n\n\n(Go up to heading level 6 with ######)\n\n\n\n\n\n\n\n\nLink text\n\n\n\n\nLink text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;code&gt;Inline code with backticks\n\n\n\n\nInline code with backticks\n\n\n\n\n&gt; Blockquote\n\n\n\n\n\n\nBlockquote\n\n\n\n\n\n\n- Things in\n- an unordered\n- list\n\n\n* Things in\n* an unordered\n* list\n\n\n\n\nThings in\n\n\nan unordered\n\n\nlist\n\n\n\n\n\n\n1. Things in\n2. an ordered\n3. list\n\n\n1) Things in\n2) an ordered\n3) list\n\n\n\n\nThings in\n\n\nan ordered\n\n\nlist\n\n\n\n\n\n\nHorizontal line\n\n---\n\n\nHorizontal line\n\n***\n\n\n\nHorizontal line"
  },
  {
    "objectID": "resource/markdown.html#math",
    "href": "resource/markdown.html#math",
    "title": "Using Markdown",
    "section": "Math",
    "text": "Math\n\nBasic math commands\nMarkdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here. In this class, these will be the most common things you’ll use:\n\n\n\n\n\nDescription\nCommand\nOutput\n\n\n\n\nLetters\n\n\nRoman letters\n&lt;code&gt;a b c d e f&lt;/code&gt;\n\\(a\\ b\\ c\\ d\\ e\\ f\\)\n\n\nGreek letters (see &lt;a href='https://www.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols'&gt;this&lt;/a&gt; for all possible letters)\n&lt;code&gt;\\alpha \\beta \\Gamma \\gamma&lt;/code&gt; &lt;br&gt; &lt;code&gt;\\Delta \\delta \\epsilon&lt;/code&gt;\n\\(\\alpha\\ \\beta\\ \\Gamma\\ \\gamma\\ \\Delta\\ \\delta\\ \\epsilon\\)\n\n\nLetters will automatically be italicized and treated as math variables;&lt;br&gt;if you want actual text in the math, use &lt;code&gt;\\text{}&lt;/code&gt;\nEw: &lt;code&gt;Treatment = \\beta&lt;/code&gt; &lt;br&gt;Good: &lt;code&gt;\\text{Treatment} = \\beta&lt;/code&gt;\nEw: \\(Treatment = \\beta\\)&lt;br&gt;Good: \\(\\text{Treatment} = \\beta\\)\n\n\nExtra spaces will automatically be removed; if you want a space, use &lt;code&gt;\\ &lt;/code&gt;\nNo space: &lt;code&gt;x y&lt;/code&gt; &lt;br&gt; Space: &lt;code&gt;x\\ y&lt;/code&gt;\nNo space: \\(x y\\) &lt;br&gt;Space: \\(x \\ y\\)\n\n\nSuperscripts and subscripts\n\n\nUse &lt;code&gt;^&lt;/code&gt; to make one character superscripted.\n&lt;code&gt;x^2&lt;/code&gt;\n\\(x^2\\)\n\n\nWrap the superscripted part in &lt;code&gt;{}&lt;/code&gt; if there's more than one character\n&lt;code&gt;x^{2+y}&lt;/code&gt;\n\\(x^{2+y}\\)\n\n\nUse &lt;code&gt;_&lt;/code&gt; to make one character subscripted\n&lt;code&gt;\\beta_1&lt;/code&gt;\n\\(\\beta_1\\)\n\n\nWrap the subscripted part in &lt;code&gt;{}&lt;/code&gt; if there's more than one character\n&lt;code&gt;\\beta_{i, t}&lt;/code&gt;\n\\(\\beta_{i, t}\\)\n\n\nUse superscripts and subscripts simultaneously\n&lt;code&gt;\\beta_1^{\\text{Treatment}}&lt;/code&gt;\n\\(\\beta_1^{\\text{Treatment}}\\)\n\n\nYou can even nest them\n&lt;code&gt;x^{2^{2^2}}&lt;/code&gt;\n\\(x^{2^{2^2}}\\)\n\n\nMath operations\n\n\nAddition\n&lt;code&gt;2 + 5 = 7&lt;/code&gt;\n\\(2 + 5 = 7\\)\n\n\nSubtraction\n&lt;code&gt;2 - 5 = -3&lt;/code&gt;\n\\(2 + 5 = -3\\)\n\n\nMultiplication\n&lt;code&gt;x \\times y&lt;/code&gt; &lt;br&gt; &lt;code&gt;x \\cdot y&lt;/code&gt;\n\\(x \\times y\\) &lt;br&gt; \\(x \\cdot y\\)\n\n\nDivision\n&lt;code&gt;8 \\div 2&lt;/code&gt;\n\\(8 \\div 2\\)\n\n\nFractions\n&lt;code&gt;\\frac{8}{2}&lt;/code&gt;\n\\(\\frac{8}{2}\\)\n\n\nSquare roots; use &lt;code&gt;[3]&lt;/code&gt; for other roots\n&lt;code&gt;\\sqrt{81} = 9&lt;/code&gt; &lt;br&gt; &lt;code&gt;\\sqrt[3]{27} = 3&lt;/code&gt;\n\\(\\sqrt{81} = 9\\) &lt;br&gt; \\(\\sqrt[3]{27} = 3\\)\n\n\nSummation; use sub/superscripts for extra details\n&lt;code&gt;\\sum x&lt;/code&gt; &lt;br&gt; &lt;code&gt;\\sum_{n=1}^{\\infty} \\frac{1}{n}&lt;/code&gt;\n\\(\\sum x\\) &lt;br&gt; \\(\\sum_{n=1}^{\\infty} \\frac{1}{n}\\)\n\n\nProducts; use sub/superscripts for extra details\n&lt;code&gt;\\prod x&lt;/code&gt; &lt;br&gt; &lt;code&gt;\\prod_{n=1}^{5} n^2&lt;/code&gt;\n\\(\\prod x\\) &lt;br&gt; \\(\\prod_{n=1}^{5} n^2\\)\n\n\nIntegrals; use sub/superscripts for extra details\n&lt;code&gt;\\int x^2 \\ dx&lt;/code&gt; &lt;br&gt; &lt;code&gt;\\int_{1}^{100} x^2 \\ dx&lt;/code&gt;\n\\(\\int x^2 \\ dx\\) &lt;br&gt; \\(\\int_{1}^{100} x^2 \\ dx\\)\n\n\nExtra symbols\n\n\nAdd a bar for things like averages\n&lt;code&gt;\\bar{x}&lt;/code&gt;\n\\(\\bar{x}\\)\n\n\nUse an overline for longer things\nEw: &lt;code&gt;\\bar{abcdef}&lt;/code&gt; &lt;br&gt; Good: &lt;code&gt;\\overline{abcdef}&lt;/code&gt;\nEw: \\(\\bar{abcdef}\\) &lt;br&gt; Good: \\(\\overline{abcdef}\\)\n\n\nAdd a hat for things like estimates\n&lt;code&gt;\\hat{y}&lt;/code&gt;\n\\(\\hat{y}\\)\n\n\nUse a wide hat for longer things\nEw: &lt;code&gt;\\hat{abcdef}&lt;/code&gt; &lt;br&gt; Good: &lt;code&gt;\\widehat{abcdef}&lt;/code&gt;\nEw: \\(\\hat{abcdef}\\) &lt;br&gt; Good: \\(\\widehat{abcdef}\\)\n\n\nUse arrows for DAG-like things\n&lt;code&gt;Z \\rightarrow Y \\leftarrow X&lt;/code&gt;\n\\(Z \\rightarrow Y \\leftarrow X\\)\n\n\nBonus fun\n\n\nUse colors!; see &lt;a href='https://www.overleaf.com/learn/latex/Using_colours_in_LaTeX'&gt;here&lt;/a&gt; for more details and &lt;a href='https://www.overleaf.com/learn/latex/Using_colours_in_LaTeX#Reference_guide'&gt;here&lt;/a&gt; for a list of color names\n&lt;code&gt;\\color{red}{y} = \\color{blue}{\\beta_1 x_1}&lt;/code&gt;\n\\(\\color{red}{y}\\ \\color{black}{=}\\ \\color{blue}{\\beta_1 x_1}\\)\n\n\n\n\n\n\n\n\n\nUsing math inline\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n\n\n\n\n\n\n\n\n\nType…\n\n\n…to get\n\n\n\n\n\n\nBased on the DAG, the regression model for\nestimating the effect of education on wages\nis $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, \nor $\\text{Wages} = \\beta_0 + \n\\beta_1 \\text{Education} + \\epsilon$.\n\n\nBased on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\).\n\n\n\n\n\n\n\nUsing math in a block\nTo put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was a way to solve for $x$ in high school math:\n\n$$\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n$$\n…to get…\n\nThe quadratic equation was a way to solve for \\(x\\) in high school math:\n\\[\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\]\n\n\n\n\nDollar signs and math\nBecause dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs \\($5.75 and this other costs $40\\)”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”."
  },
  {
    "objectID": "resource/markdown.html#tables",
    "href": "resource/markdown.html#tables",
    "title": "Using Markdown",
    "section": "Tables",
    "text": "Tables\nThere are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like kableExtra (use kable()) or pander (use pandoc.table()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\n  Right     Left     Center     Default\n-------     ------ ----------   -------\n     12     12        12            12\n    123     123       123          123\n      1     1          1             1\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nCenter\nDefault\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\nFor pipe tables, type…\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "resource/markdown.html#footnotes",
    "href": "resource/markdown.html#footnotes",
    "title": "Using Markdown",
    "section": "Footnotes",
    "text": "Footnotes\nThere are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags].\n\n[^1]: This is a note.\n\n[^note-on-dags]: DAGs are neat. \n\nAnd here's more of the document.\n…to get…\n\nHere is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n\n\n\n\n\nThis is a note.↩︎\n\n\n\n\nDAGs are neat.↩︎\n\n\n\n\n\n\nYou can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!]\n…to get…\n\nCausal inference is neat.1\n\n\n\n\n\nBut it can be hard too!↩︎"
  },
  {
    "objectID": "resource/markdown.html#front-matter",
    "href": "resource/markdown.html#front-matter",
    "title": "Using Markdown",
    "section": "Front matter",
    "text": "Front matter\nYou can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\n---\nYou can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n---\ntitle: \"My cool title: a subtitle\"\n---\nIf you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n---\ntitle: 'An evaluation of \"scare quotes\"'\n---"
  },
  {
    "objectID": "resource/markdown.html#citations",
    "href": "resource/markdown.html#citations",
    "title": "Using Markdown",
    "section": "Citations",
    "text": "Citations\nOne of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\n\nAdd a bibliography: entry to the YAML metadata:\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\n---\nChoose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\ncsl: \"https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\"\n---\nSome of the most common CSLs are:\n\nChicago author-date\nChicago note-bibliography\nChicago full note-bibliography (no shortened notes or ibids)\nAPA 7th edition\nMLA 8th edition\n\nCite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n\n\n\n\n\n\n\n\nType…\n…to get…\n\n\n\n\nCausal inference is neat [@Rohrer:2018;\n@AngristPischke:2015].\nCausal inference is neat (Rohrer 2018; Angrist and Pischke 2015).\n\n\nCausal inference is neat [see @Rohrer:2018,\np. 34; also @AngristPischke:2015, chapter 1]\nCausal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1)\n\n\nAngrist and Pischke say causal inference\nis neat [-@AngristPischke:2015; see also\n@Rohrer:2018].\nAngrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).\n\n\n@AngristPischke:2015 [chapter 1] say causal\ninference is neat, and @Rohrer:2018 agrees.\nAngrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees.\n\n\n\nAfter compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629."
  },
  {
    "objectID": "resource/markdown.html#other-references",
    "href": "resource/markdown.html#other-references",
    "title": "Using Markdown",
    "section": "Other references",
    "text": "Other references\nThese websites have additional details and examples and practice tools:\n\nCommonMark’s Markdown tutorial: A quick interactive Markdown tutorial.\nMarkdown tutorial: Another interactive tutorial to practice using Markdown.\nMarkdown cheatsheet: Useful one-page reminder of Markdown syntax.\nThe Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown."
  },
  {
    "objectID": "resource/rmarkdown.html",
    "href": "resource/rmarkdown.html",
    "title": "Using R Markdown",
    "section": "",
    "text": "R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:"
  },
  {
    "objectID": "resource/rmarkdown.html#key-terms",
    "href": "resource/rmarkdown.html#key-terms",
    "title": "Using R Markdown",
    "section": "Key terms",
    "text": "Key terms\n\nDocument: A Markdown file where you type stuff\nChunk: A piece of R code that is included in your document. It looks like this:\n\n```{r}\n# Code goes here\n```\n\nThere must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\nKnit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows."
  },
  {
    "objectID": "resource/rmarkdown.html#add-chunks",
    "href": "resource/rmarkdown.html#add-chunks",
    "title": "Using R Markdown",
    "section": "Add chunks",
    "text": "Add chunks\nThere are three ways to insert chunks:\n\nPress ⌘⌥I on macOS or control + alt + I on Windows\nClick on the “Insert” button at the top of the editor window\n\n\n\n\n\n\n\n\n\n\n\nManually type all the backticks and curly braces (don’t do this)"
  },
  {
    "objectID": "resource/rmarkdown.html#chunk-names",
    "href": "resource/rmarkdown.html#chunk-names",
    "title": "Using R Markdown",
    "section": "Chunk names",
    "text": "Chunk names\nYou can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\n\n\n\n\n\n\n\n\n\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk}\n# Code goes here\n```"
  },
  {
    "objectID": "resource/rmarkdown.html#chunk-options",
    "href": "resource/rmarkdown.html#chunk-options",
    "title": "Using R Markdown",
    "section": "Chunk options",
    "text": "Chunk options\nThere are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE}\n# Code goes here\n```\nThe most common chunk options are these:\n\nfig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures\necho=FALSE: The code is not shown in the final document, but the results are\nmessage=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted\nwarning=FALSE: Any warnings that R generates are omitted\ninclude=FALSE: The chunk still runs, but the code and results are not included in the final document\n\nYou can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:"
  },
  {
    "objectID": "resource/rmarkdown.html#inline-chunks",
    "href": "resource/rmarkdown.html#inline-chunks",
    "title": "Using R Markdown",
    "section": "Inline chunks",
    "text": "Inline chunks\nYou can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE}\navg_mpg &lt;- mean(mtcars$mpg)\n```\n\nThe average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon.\n… would knit into this:\n\nThe average fuel efficiency for cars from 1974 was 20.1 miles per gallon."
  },
  {
    "objectID": "resource/rmarkdown.html#output-formats",
    "href": "resource/rmarkdown.html#output-formats",
    "title": "Using R Markdown",
    "section": "Output formats",
    "text": "Output formats\nYou can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \"My document\"\noutput:\n  html_document: default\n  pdf_document: default\n  word_document: default\nYou can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\n\n\n\n\n\n\n\n\n\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n---\ntitle: \"My document\"\nauthor: \"My name\"\ndate: \"January 13, 2020\"\noutput: \n  html_document: \n    toc: yes\n    fig_caption: yes\n    fig_height: 8\n    fig_width: 10\n  pdf_document: \n    latex_engine: xelatex  # More modern PDF typesetting engine\n    toc: yes\n  word_document: \n    toc: yes\n    fig_caption: yes\n    fig_height: 4\n    fig_width: 5\n---"
  },
  {
    "objectID": "resource/unzipping.html",
    "href": "resource/unzipping.html",
    "title": "Unzipping files",
    "section": "",
    "text": "Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.\nUnzipping files on macOS is trivial, but unzipping files on Windows can mess you up if you don’t pay careful attention. Here’s a helpful guide to unzipping files on both macOS and Windows."
  },
  {
    "objectID": "resource/unzipping.html#unzipping-files-on-macos",
    "href": "resource/unzipping.html#unzipping-files-on-macos",
    "title": "Unzipping files",
    "section": "Unzipping files on macOS",
    "text": "Unzipping files on macOS\nDouble click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started."
  },
  {
    "objectID": "resource/unzipping.html#unzipping-files-on-windows",
    "href": "resource/unzipping.html#unzipping-files-on-windows",
    "title": "Unzipping files",
    "section": "Unzipping files on Windows",
    "text": "Unzipping files on Windows\ntl;dr: Right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This can be is incredibly confusing! Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top, and there’s a “Ratio” column that shows how much each file is compressed.\n\n\n\n\n\nIt is very tempting to try to open files from this view. However, if you do, things will break and you won’t be able to correctly work with any of the files in the zipped folder. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\n\n\n\n\n\nYou most likely won’t be able to open any data files or save anything, which will be frustrating.\nInstead, you need to right click on the .zip file and select “Extract All…”:\n\n\n\n\n\nThen choose where you want to unzip all the files and click on “Extract”\n\n\n\n\n\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester!\n\nContent (): This page contains the readings, slides, and recorded lectures for the week. Read and watch these before our in-person class.\nExample (): This page contains fully annotated R code and other supplementary information that you can use as a reference for your assignments and project. This is only a reference page—you don’t have to necessarily do anything here. Some sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. This page will be very helpful as you work on your assignments.\nAssignment (): This page contains the instructions for each assignment. Weekly reports are due by noon on the day of class. Other assignments are due by 11:59 PM on the day they’re listed.\n\n\n\n\n\n\n\nSubscribe!\n\n\n\nYou can subscribe to this calendar URL in Outlook, Google Calendar, or Apple Calendar:\n\n\n\n Download\n\n\n\n\n\n\n\n\n\n\n\nEvaluation and causation\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 1\n\n\n\n\nAugust 22\n\n\nEvaluation and the causal revolution\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugust 29\n\n\nWeekly check-in 1  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugust 29\n\n\nProblem set 1  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 2\n\n\n\n\nAugust 29\n\n\nRegression and inference\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugust 29\n\n\nWeekly check-in 2  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 6\n\n\nProblem set 2  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 3\n\n\n\n\nSeptember 5\n\n\nTheories of change and logic models(No class because of Labor Day—we’ll talk about this content in class on September 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 6\n\n\nWeekly check-in 3  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 12\n\n\nEvaluation: Background and theory  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 4\n\n\n\n\nSeptember 12\n\n\nMeasurement and DAGs\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 12\n\n\nWeekly check-in 4  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 19\n\n\nEvaluation: Measurement  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 5\n\n\n\n\nSeptember 19\n\n\nDAGs and potential outcomes\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 19\n\n\nWeekly check-in 5  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 26\n\n\nEvaluation: Causal model  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 6\n\n\n\n\nSeptember 26\n\n\nThreats to validity\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 26\n\n\nWeekly check-in 6  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 3\n\n\nEvaluation: Threats to validity  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 1\n\n\n\n\nOctober 3–October 9\n\n\nExam 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools and methods\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 7\n\n\n\n\nOctober 3\n\n\nRandomization and matching\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 3\n\n\nWeekly check-in 7  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 10\n\n\nProblem set 3  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 8\n\n\n\n\nOctober 10\n\n\nDifference-in-differences I\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 10\n\n\nWeekly check-in 8  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 17\n\n\nProblem set 4  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 9\n\n\n\n\nOctober 17\n\n\nDifference-in-differences II\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 17\n\n\nWeekly check-in 9  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 24\n\n\nProblem set 5  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 10\n\n\n\n\nOctober 24\n\n\nRegression discontinuity I\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 24\n\n\nWeekly check-in 10  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 31\n\n\nProblem set 6  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 11\n\n\n\n\nOctober 31\n\n\nInstrumental variables I\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 31\n\n\nWeekly check-in 11  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 7\n\n\nProblem set 7  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 12\n\n\n\n\nNovember 7\n\n\nInstrumental variables II + Regression discontinuity II\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 7\n\n\nWeekly check-in 12  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 14\n\n\nProblem set 8  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 2\n\n\n\n\nNovember 14–November 20\n\n\nExam 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplied evaluation\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 13\n\n\n\n\nNovember 14\n\n\nChoosing and planning ethical evaluations\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 14\n\n\nWeekly check-in 13  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 28\n\n\nProblem set 9  (submit by 11:59 PM)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 14\n\n\n\n\nNovember 28\n\n\nEthics, stories, and curiosity\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 28\n\n\nWeekly check-in 14  (submit by noon)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nFinal project\n\n\n\n\nDecember 12\n\n\nFinal project due"
  }
]